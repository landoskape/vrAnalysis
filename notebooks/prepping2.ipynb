{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Working on a big refactor here...\n",
    "moving towards vrAnalysis2\n",
    "\n",
    "Objectives:\n",
    "- Build dataclass structure for imaging and behavior sessions that I can operate on\n",
    "across datatypes - I want to run the same code on my data and external data\n",
    "- Simplify analyses by building a set of functions that can be called on these dataclasses\n",
    "instead of extending analysis classes for each kind of analysis\n",
    "- Rewrite standard scripts to do analyses with this new refactor\n",
    "\n",
    "\n",
    "I should think about the key requirements for analyzing behavior and imaging data for\n",
    "vr navigation and structure around that. Things that I do:\n",
    "\n",
    "Basic data handling:\n",
    "- Load spiking data\n",
    "- Load behavior data (position, speed, etc)\n",
    "- Load ROI data\n",
    "\n",
    "Processing:\n",
    "- Make a spkmap\n",
    "- Process spkmaps\n",
    "- Filter and sort ROIs by tracked (or other criteria, like plane_idx...)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Ideas:\n",
    "An analysis object which can be loaded that isn't necessarily connect to any data. You can pass in a list\n",
    "of data objects to it and it will run the analysis on all of them. This way I can run the same analysis on\n",
    "my data and external data, compare within a mouse, across mice, etc.\n",
    "\n",
    "There can be a \"flag\" for same mice with tracker, in which case it can perform special operations like aligning\n",
    "ROIs across sessions by tracked ROI etc. \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Updates / Work in progress:\n",
    "- I've got the b2session working. I think it's good. There might be more to add or reorganize, but essentially it's\n",
    "  ready to go because it can find the onedata, load spks in a clever way, and has a few other tools for loading. \n",
    "- Now I think I can just keep working on everything that comes after this... e.g. on the analysis class side of things\n",
    "  which might need a lot of refactoring (or maybe not???)\n",
    "- The registration stuff will be nice to refactor to this method, but for now I can hack it and just use both I guess?\n",
    "\"\"\"\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import perf_counter\n",
    "from vrAnalysis2.sessions import create_b2session\n",
    "from vrAnalysis2.processors.spkmaps import SpkmapProcessor, SpkmapParams\n",
    "mouse_name = \"ATL027\"\n",
    "date = \"2023-07-27\"\n",
    "session_id = \"701\"\n",
    "spks_type = \"significant\"\n",
    "\n",
    "session = create_b2session(mouse_name, date, session_id, spks_type)\n",
    "spkmap_processor = SpkmapProcessor(session, params={\"autosave\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpkmapParams(dist_step=1.0, speed_threshold=1.0, speed_max_allowed=inf, full_trial_flexibility=3.0, standardize_spks=True, smooth_width=1.0, autosave=True)\n"
     ]
    }
   ],
   "source": [
    "print(spkmap_processor.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/localData/ATL012/2023-01-23/701/spkmaps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spkmap_processor.cache_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = spkmap_processor.get_env_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6145011000335217\n"
     ]
    }
   ],
   "source": [
    "from vrAnalysis2 import helpers\n",
    "t = perf_counter()\n",
    "rel = [helpers.reliability_loo(spkmap) for spkmap in maps.spkmap]\n",
    "print(perf_counter() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maps(occmap: [(45, 195), (53, 195)], speedmap: [(45, 195), (53, 195)], spkmap: [(12716, 45, 195), (12716, 53, 195)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO LIST\n",
    "# - Need to add the auxiliary methods like reliability and frame behavior etc\n",
    "# - Build system for filtering ROIs by flyback plane and duplicates and good cells, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from vrAnalysis2.external.pettit2022 import find_pettit_harvey_sessions, data_path\n",
    "sessions = find_pettit_harvey_sessions(data_path / \"dataFolder\")\n",
    "\n",
    "behavior = sessions[0].behavior\n",
    "spks = sessions[0].spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from vrAnalysis2 import files\n",
    "from vrAnalysis import database\n",
    "sessiondb = database.vrDatabase('vrSessions')\n",
    "from typing import Union\n",
    "\n",
    "def find_experiment_options(root_dir: Union[str, Path]) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Find all vrExperimentOptions.json files in the given directory and its subdirectories.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    root_dir : str or Path\n",
    "        The root directory to start the search from\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list[Path]\n",
    "        List of paths to all matching files\n",
    "    \"\"\"\n",
    "    def make_identifier(pth: Path) -> list[str]:\n",
    "        return \"_\".join(list(reversed([p.stem for p in list(pth.parents)[:3]])))\n",
    "    \n",
    "    root_path = Path(root_dir)\n",
    "    all_paths = list(root_path.rglob(\"vrExperimentOptions.json\"))\n",
    "    session_identifier = [make_identifier(pth) for pth in all_paths]\n",
    "    return all_paths, session_identifier\n",
    "\n",
    "pths, sids = find_experiment_options(files.local_data_path())\n",
    "csesids = [sessiondb.sessionPrint(joinby=\"_\") for sessiondb in sessiondb.iterSessions(useDefault=True)]\n",
    "\n",
    "for sid in sids:\n",
    "    if sid not in csesids:\n",
    "        print(\"oops\", sid)\n",
    "\n",
    "for ses in sessiondb.iterSessions():\n",
    "    csesid = ses.sessionPrint(joinby=\"_\")\n",
    "    print(csesid, csesid in sids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
