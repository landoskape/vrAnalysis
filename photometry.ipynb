{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import re\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import detrend\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from vrAnalysis import fileManagement as files\n",
    "from vrAnalysis.helpers import errorPlot\n",
    "\n",
    "data_path = files.localDataPath()\n",
    "\n",
    "file_tree = dict(\n",
    "    in_time = \"DataAcquisition/FPConsole/Signals/Series0001/AnalogIn/Time\",\n",
    "    in_data = \"DataAcquisition/FPConsole/Signals/Series0001/AnalogIn/AIN03\",\n",
    "    out_time = \"DataAcquisition/FPConsole/Signals/Series0001/AnalogOut/Time\",\n",
    "    out1 = \"DataAcquisition/FPConsole/Signals/Series0001/AnalogOut/AOUT01\",\n",
    "    out2 = \"DataAcquisition/FPConsole/Signals/Series0001/AnalogOut/AOUT02\",\n",
    "    out3 = \"DataAcquisition/FPConsole/Signals/Series0001/AnalogOut/AOUT03\",\n",
    ")\n",
    "\n",
    "def create_file_dict(file):\n",
    "    data = {}\n",
    "    for key, value in file_tree.items():\n",
    "        data[key] = np.array(file[value])\n",
    "    return data\n",
    "\n",
    "def get_doric_files(mouse_name):\n",
    "    \"\"\"Get all doric files and there dates from the data path\"\"\"\n",
    "    directory = []\n",
    "    file_index = []\n",
    "    data = []\n",
    "    mouse_directory = data_path / mouse_name\n",
    "    date_directories = [x for x in mouse_directory.iterdir() if x.is_dir()]\n",
    "    for date_directory in date_directories:\n",
    "        for file in date_directory.glob('*.doric'):\n",
    "            file_index_match = re.match(r'.*_(\\d+).doric', file.name)\n",
    "            if file_index_match:\n",
    "                c_file_index = int(file_index_match.group(1))\n",
    "            else:\n",
    "                print(f\"Could not parse file index from {file.parent}/{file.name}\")\n",
    "                continue\n",
    "            with h5py.File(file, 'r') as f:\n",
    "                file_data = create_file_dict(f)\n",
    "            file_index.append(c_file_index)\n",
    "            directory.append(date_directory.name)\n",
    "            file_data[\"index\"] = file_index\n",
    "            data.append(file_data)\n",
    "    return directory, file_index, data\n",
    "\n",
    "def check_doric_filetree(mouse_name):\n",
    "    \"\"\"Find a doric file and print the filetree to inspect contents\"\"\"\n",
    "    mouse_directory = data_path / mouse_name\n",
    "    date_directories = [x for x in mouse_directory.iterdir() if x.is_dir()]\n",
    "    for date_directory in date_directories:\n",
    "        for file in date_directory.glob('*.doric'):\n",
    "            file_index_match = re.match(r'.*_(\\d+).doric', file.name)\n",
    "            if file_index_match:\n",
    "                c_file_index = int(file_index_match.group(1))\n",
    "            else:\n",
    "                raise ValueError(f\"Could not parse file index from {file.name}\")\n",
    "            with h5py.File(file, 'r') as f:\n",
    "                # Print the full filetree\n",
    "                f.visit(print)\n",
    "            return None\n",
    "        \n",
    "def _filter_cycle_markers(markers, first, last, keep_first=False, keep_last=False):\n",
    "    \"\"\"Filter cycle markers to only include valid cycles.\"\"\"\n",
    "    if keep_first:\n",
    "        markers = markers[markers >= first]\n",
    "    else:\n",
    "        markers = markers[markers > first]\n",
    "    if keep_last:\n",
    "        markers = markers[markers <= last]\n",
    "    else:\n",
    "        markers = markers[markers < last]\n",
    "    return markers\n",
    "\n",
    "def get_cycles(data, cycle_period_tolerance=0.1):\n",
    "    \"\"\"Get output cycles with interleaved data on out1 and out2.\n",
    "    \n",
    "    Find start stop indices for each cycle. \n",
    "    Check that the cycles are interleaved correctly.\n",
    "    Return the start and stop indices for each cycle.\n",
    "    Return an index to all samples within the target cycles.\n",
    "\n",
    "    Target cycle definition:\n",
    "    First cycle is always on out1 (will clip if necessary) - last cycle is out2. \n",
    "    \"\"\"\n",
    "    diff1 = np.diff(data[\"out1\"])\n",
    "    diff2 = np.diff(data[\"out2\"])\n",
    "    start1 = np.where(diff1 == 1)[0] + 1\n",
    "    start2 = np.where(diff2 == 1)[0] + 1\n",
    "    stop1 = np.where(diff1 == -1)[0] + 1\n",
    "    stop2 = np.where(diff2 == -1)[0] + 1\n",
    "    first_valid_idx = start1[0]\n",
    "    last_valid_idx = stop2[-1]\n",
    "\n",
    "    start1 = _filter_cycle_markers(start1, first_valid_idx, last_valid_idx, keep_first=True)\n",
    "    start2 = _filter_cycle_markers(start2, first_valid_idx, last_valid_idx)\n",
    "    stop1 = _filter_cycle_markers(stop1, first_valid_idx, last_valid_idx)\n",
    "    stop2 = _filter_cycle_markers(stop2, first_valid_idx, last_valid_idx, keep_last=True)\n",
    "\n",
    "    start1 = _filter_cycle_markers(start1, first_valid_idx, stop1[-1], keep_first=True)\n",
    "    stop2 = _filter_cycle_markers(stop2, start2[0], last_valid_idx, keep_last=True)\n",
    "    \n",
    "    if len(start1) != len(start2):\n",
    "        raise ValueError(\"Unequal number of start markers\")\n",
    "    if len(stop1) != len(stop2):\n",
    "        raise ValueError(\"Unequal number of stop markers\")\n",
    "    if len(start1) != len(stop1):\n",
    "        raise ValueError(\"Unequal number of start and stop markers\")\n",
    "    if not np.all(start1 < stop1):\n",
    "        raise ValueError(\"Start marker after stop marker for channel 1\")\n",
    "    if not np.all(start2 < stop2):\n",
    "        raise ValueError(\"Start marker after stop marker for channel 2\")\n",
    "    \n",
    "    period1 = stop1 - start1\n",
    "    period2 = stop2 - start2\n",
    "    period1_deviation = period1 / np.mean(period1)\n",
    "    period2_deviation = period2 / np.mean(period2)\n",
    "    bad_period1 = np.abs(period1_deviation - 1) > cycle_period_tolerance\n",
    "    bad_period2 = np.abs(period2_deviation - 1) > cycle_period_tolerance\n",
    "    if np.sum(np.diff(np.where(bad_period1)[0]) < 2) > 2:\n",
    "        raise ValueError(\"Too many consecutive bad periods in channel 1\")\n",
    "    if np.sum(np.diff(np.where(bad_period2)[0]) < 2) > 2:\n",
    "        raise ValueError(\"Too many consecutive bad periods in channel 2\")\n",
    "    \n",
    "    # Remove bad periods and filter stop / start signals\n",
    "    valid_period = ~bad_period1 & ~bad_period2\n",
    "    start1 = start1[valid_period]\n",
    "    stop1 = stop1[valid_period]\n",
    "    start2 = start2[valid_period]\n",
    "    stop2 = stop2[valid_period]\n",
    "\n",
    "    if not np.all(data[\"out1\"][start1] == 1) or not np.all(data[\"out2\"][start2] == 1):\n",
    "        raise ValueError(\"Start indices are not positive for out1 / out2!\")\n",
    "    if not np.all(data[\"out1\"][stop1] == 0) or not np.all(data[\"out2\"][stop2] == 0):\n",
    "        raise ValueError(\"Stop indices are not zero for out1 / out2!\")\n",
    "    \n",
    "    return start1, stop1, start2, stop2\n",
    "\n",
    "def get_opto_cycles(data, min_period=1, cycle_period_tolerance=0.01):\n",
    "    \"\"\"Get opto cycles (out3) with a minimum period.\n",
    "    \n",
    "    Returns the start times for each cycle and an average cycle signal. \n",
    "    \"\"\"\n",
    "    diff3 = np.diff(data[\"out3\"])\n",
    "    start3 = np.where(diff3 == 1)[0] + 1\n",
    "    stop3 = np.where(diff3 == -1)[0] + 1\n",
    "    first_valid_idx = start3[0]\n",
    "    last_valid_idx = stop3[-1]\n",
    "    start3 = _filter_cycle_markers(start3, first_valid_idx, last_valid_idx, keep_first=True)\n",
    "    start_time = data[\"out_time\"][start3]\n",
    "\n",
    "    valid_starts = [start3[0]]\n",
    "    valid_times = [start_time[0]]\n",
    "\n",
    "    for i in range(1, len(start3)):\n",
    "        if start_time[i] > (valid_times[-1] + min_period):\n",
    "            valid_starts.append(start3[i])\n",
    "            valid_times.append(start_time[i])\n",
    "\n",
    "    # Convert valid starts to numpy array (reuse start3 for consistent terminology with get_cycles)\n",
    "    start3 = np.array(valid_starts)\n",
    "\n",
    "    # Measure period between cycles\n",
    "    period3 = start3[1:] - start3[:-1]\n",
    "    period3_deviation = period3 / np.mean(period3)\n",
    "    if not np.all(period3_deviation >= 1-cycle_period_tolerance) and np.all(period3_deviation <= 1+cycle_period_tolerance):\n",
    "        min_period = np.min(period3)\n",
    "        max_period = np.max(period3)\n",
    "        raise ValueError(f\"Excess period variation in opto cycles! min={min_period:.2f}, max={max_period:.2f}\")\n",
    "    \n",
    "    min_period = np.min(period3)\n",
    "    stop3 = start3 + min_period\n",
    "\n",
    "    if stop3[-1] >= len(data[\"out3\"]):\n",
    "        start3 = start3[:-1]\n",
    "        stop3 = stop3[:-1]\n",
    "\n",
    "    cycles = []\n",
    "    for istart, istop in zip(start3, stop3):\n",
    "        cycles.append(data[\"out3\"][istart:istop])\n",
    "    average_cycle = np.mean(np.stack(cycles), axis=0)\n",
    "    \n",
    "    return start3, stop3, average_cycle\n",
    "\n",
    "def get_cycle_data(signal, start, stop, keep_fraction=0.5, signal_cv_tolerance=0.05):\n",
    "    \"\"\"Extract cycle data from a signal.\"\"\"\n",
    "    num_samples = len(start)\n",
    "    assert keep_fraction > 0 and keep_fraction < 1, \"Invalid keep_fraction, must be in between 0 and 1\"\n",
    "    assert num_samples == len(stop), \"Start and stop indices mismatch\"\n",
    "    cycle_data = []\n",
    "    invalid_cycle = []\n",
    "    for i in range(num_samples):\n",
    "        c_stop = stop[i] - 1\n",
    "        c_start = start[i] + int(keep_fraction * (c_stop - start[i]))\n",
    "        cycle_signal = signal[c_start:c_stop]\n",
    "        cycle_cv = np.std(cycle_signal) / np.mean(cycle_signal)\n",
    "        invalid_cycle.append(cycle_cv > signal_cv_tolerance)\n",
    "        cycle_data.append(signal[c_start:c_stop])\n",
    "    cycle_data = np.array([np.mean(cd) for cd in cycle_data])\n",
    "    return cycle_data, np.array(invalid_cycle)\n",
    "    \n",
    "def analyze_data(data, preperiod=0.1, cycle_period_tolerance=0.5, keep_fraction=0.5, signal_cv_tolerance=0.05):\n",
    "    \"\"\"Process a data file, return results and filtered signals.\"\"\"\n",
    "    # First check if the data is valid and meets criteria for processing.\n",
    "    num_samples = len(data[\"in_data\"])\n",
    "    if not num_samples > 0:\n",
    "        raise ValueError(\"No data found! in_data has 0 samples.\")\n",
    "    for key in [\"out1\", \"out2\", \"out3\"]:\n",
    "        assert num_samples == len(data[key]), f\"{key} and in_data length mismatch\"\n",
    "        uvals = np.unique(data[key])\n",
    "        if not np.array_equal(uvals, np.array([0.0, 1.0])):\n",
    "            raise ValueError(f\"Invalid values in {key}: {uvals}\")\n",
    "    for key in [\"in_time\", \"out_time\"]:\n",
    "        assert num_samples == len(data[key]), f\"{key} and in_data length mismatch\"\n",
    "    \n",
    "    # Get start and top indices for the interleaved cycles\n",
    "    time = data[\"in_time\"]\n",
    "    start1, stop1, start2, stop2 = get_cycles(data, cycle_period_tolerance=cycle_period_tolerance) \n",
    "    cycle_timestamps = (time[stop2] + time[start1]) / 2 # Midpoint of full cycles\n",
    "    in1, invalid1 = get_cycle_data(data[\"in_data\"], start1, stop1, keep_fraction=keep_fraction, signal_cv_tolerance=signal_cv_tolerance)\n",
    "    in2, invalid2 = get_cycle_data(data[\"in_data\"], start2, stop2, keep_fraction=keep_fraction, signal_cv_tolerance=signal_cv_tolerance)\n",
    "    \n",
    "    # Upsample the cycle data to match the original timestamps\n",
    "    upsample_cycle_timestamps = time[(time >= cycle_timestamps[0]) & (time <= cycle_timestamps[-1])]\n",
    "    upsample_in1 = detrend(interp1d(cycle_timestamps, in1)(upsample_cycle_timestamps))\n",
    "    upsample_in2 = detrend(interp1d(cycle_timestamps, in2)(upsample_cycle_timestamps))\n",
    "    upsample_offset = np.nonzero(time >= upsample_cycle_timestamps[0])[0][0]\n",
    "\n",
    "    if np.any(invalid1) or np.any(invalid2):\n",
    "        print(f\"Warning: excess co. of var. detected for {np.sum(invalid1)/num_samples*100:.2f}% of cycles are invalid for channel 1 and {np.sum(invalid2)/num_samples*100:.2f}% for channel 2.\")\n",
    "    \n",
    "    # Get start indices for opto cycles\n",
    "    start3, stop3, _ = get_opto_cycles(data, min_period=1.0, cycle_period_tolerance=cycle_period_tolerance)\n",
    "    start3 = start3 - upsample_offset\n",
    "    stop3 = stop3 - upsample_offset\n",
    "\n",
    "    # Get opto start time in upsampled time\n",
    "    opto_start_time = upsample_cycle_timestamps[start3]\n",
    "    upsample_opto_data = data[\"out3\"][upsample_offset:]\n",
    "    upsample_opto_data = upsample_opto_data[:len(upsample_cycle_timestamps)]\n",
    "\n",
    "    samples_pre = int(preperiod / np.mean(np.diff(upsample_cycle_timestamps)))\n",
    "\n",
    "    # Get cycle data for opto cycles\n",
    "    in1_opto = []\n",
    "    in2_opto = []\n",
    "    out3_opto = []\n",
    "    time_opto = []\n",
    "    for istart, istop in zip(start3, stop3):\n",
    "        in1_opto.append(upsample_in1[istart-samples_pre:istop])\n",
    "        in2_opto.append(upsample_in2[istart-samples_pre:istop])\n",
    "        out3_opto.append(data[\"out3\"][istart+upsample_offset-samples_pre:istop+upsample_offset])\n",
    "        time_opto.append(upsample_cycle_timestamps[istart-samples_pre:istop] - upsample_cycle_timestamps[istart])\n",
    "\n",
    "    in1_opto = np.stack(in1_opto)\n",
    "    in2_opto = np.stack(in2_opto)\n",
    "    out3_opto = np.stack(out3_opto)\n",
    "    time_opto = np.mean(np.stack(time_opto), axis=0) # variance across opto cycles should be within sample error\n",
    "\n",
    "    results = dict(\n",
    "        in1_opto = in1_opto,\n",
    "        in2_opto = in2_opto,\n",
    "        out3_opto = out3_opto,\n",
    "        time_opto = time_opto,\n",
    "        opto_start_time = opto_start_time,\n",
    "        data_in1 = upsample_in1,\n",
    "        data_in2 = upsample_in2,\n",
    "        data_opto = upsample_opto_data,\n",
    "        time_data = upsample_cycle_timestamps,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 files\n"
     ]
    }
   ],
   "source": [
    "mouse_name = \"ATL065\"\n",
    "dirs, findex, data = get_doric_files(mouse_name)\n",
    "print(f\"Found {len(data)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For looking at a single session\n",
    "ises = 9\n",
    "preperiod = 0.15\n",
    "results = analyze_data(data[ises], preperiod=preperiod)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), layout=\"constrained\", sharey=False)\n",
    "ax[0].plot(results[\"time_data\"], results[\"data_in1\"], label=\"in1\")\n",
    "ax[0].plot(results[\"time_data\"], results[\"data_in2\"], label=\"in2\")\n",
    "ax[0].scatter(results[\"opto_start_time\"], np.zeros_like(results[\"opto_start_time\"]), color=\"red\", label=\"opto start\", s=5)\n",
    "\n",
    "errorPlot(results[\"time_opto\"], results[\"in1_opto\"], se=True, axis=0, label=\"in1\", ax=ax[1], alpha=0.2)\n",
    "errorPlot(results[\"time_opto\"], results[\"in2_opto\"], se=True, axis=0, label=\"in2\", ax=ax[1], alpha=0.2)\n",
    "ax[1].set_xlim(-preperiod, 0.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/9\n",
      "Processing file 2/9\n",
      "Processing file 3/9\n",
      "Processing file 4/9\n",
      "Processing file 5/9\n",
      "Processing file 6/9\n",
      "Processing file 7/9\n",
      "Processing file 8/9\n",
      "Processing file 9/9\n"
     ]
    }
   ],
   "source": [
    "# For showing a single mouse across sessions\n",
    "preperiod = 0.2\n",
    "postperiod = 1.0\n",
    "samples = np.linspace(-preperiod, postperiod, int((postperiod - preperiod) * 1000))\n",
    "\n",
    "cmap = plt.get_cmap(\"rainbow\")\n",
    "average = []\n",
    "for ifile, file in enumerate(data):\n",
    "    print(f\"Processing file {ifile+1}/{len(data)}\")\n",
    "    results = analyze_data(file, preperiod=preperiod+0.01)\n",
    "    c_idx = results[\"time_opto\"] < postperiod + preperiod\n",
    "    c_time = results[\"time_opto\"][c_idx]\n",
    "    c_data = np.mean(results[\"in2_opto\"][:, c_idx] - results[\"in1_opto\"][:, c_idx], axis=0)\n",
    "    c_interp = interp1d(c_time, c_data, kind=\"cubic\")(samples)\n",
    "    c_interp = detrend(c_interp)\n",
    "    average.append(c_interp)\n",
    "average = np.stack(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8a46ac7f0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), layout=\"constrained\")\n",
    "for iavg, avg in enumerate(average):\n",
    "    ax.plot(samples, avg, color=cmap(iavg/len(average)))\n",
    "ax.set_xlim(-preperiod, postperiod/2)\n",
    "ax.plot([0, 0.03], [-0.001, -0.001], color=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For making an average across all mice\n",
    "preperiod = 0.2\n",
    "postperiod = 1.0\n",
    "samples = np.linspace(-preperiod, postperiod, int((postperiod - preperiod) * 1000))\n",
    "\n",
    "mouse_list = [\"ATL061\", \"ATL062\", \"ATL063\", \"ATL064\", \"ATL065\"]\n",
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"brown\"]\n",
    "average = []\n",
    "for mouse in tqdm(mouse_list):\n",
    "    c_mouse_average = []    \n",
    "    dirs, findex, data = get_doric_files(mouse)\n",
    "    for file in data:\n",
    "        results = analyze_data(file, preperiod=preperiod+0.01)\n",
    "        c_idx = results[\"time_opto\"] < postperiod + preperiod\n",
    "        c_time = results[\"time_opto\"][c_idx]\n",
    "        c_data = np.mean(results[\"in2_opto\"][:, c_idx] - results[\"in1_opto\"][:, c_idx], axis=0)\n",
    "        c_interp = interp1d(c_time, c_data, kind=\"cubic\")(samples)\n",
    "        c_mouse_average.append(c_interp)\n",
    "    average.append(np.stack(c_mouse_average))\n",
    "    if mouse == \"ATL061\":\n",
    "        average[-1] = average[-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.80s/it]\n"
     ]
    }
   ],
   "source": [
    "preperiod = 0.2\n",
    "postperiod = 1.0\n",
    "samples = np.linspace(-preperiod, postperiod, int((postperiod - preperiod) * 1000))\n",
    "\n",
    "mouse_list = [\"ATL061\", \"ATL062\", \"ATL063\", \"ATL064\", \"ATL065\"]\n",
    "colors = [\"red\", \"blue\", \"green\", \"purple\", \"brown\"]\n",
    "average = []\n",
    "for mouse in tqdm(mouse_list):\n",
    "    c_mouse_average = []    \n",
    "    dirs, findex, data = get_doric_files(mouse)\n",
    "    for file in data:\n",
    "        results = analyze_data(file, preperiod=preperiod+0.01)\n",
    "        c_idx = results[\"time_opto\"] < postperiod + preperiod\n",
    "        c_time = results[\"time_opto\"][c_idx]\n",
    "        c_data = np.mean(results[\"in2_opto\"][:, c_idx] - results[\"in1_opto\"][:, c_idx], axis=0)\n",
    "        c_interp = interp1d(c_time, c_data, kind=\"cubic\")(samples)\n",
    "        c_mouse_average.append(c_interp)\n",
    "    average.append(np.stack(c_mouse_average))\n",
    "    if mouse == \"ATL061\":\n",
    "        average[-1] = average[-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x192c0849850>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), layout=\"constrained\")\n",
    "for imouse, (mouse, color, avg) in enumerate(zip(mouse_list, colors, average)):\n",
    "    errorPlot(samples, avg - np.mean(avg[:, 0]), se=True, axis=0, label=mouse, ax=ax, color=color, alpha=0.2)\n",
    "    # ax.plot(samples, avg.T, label=mouse, color=color)\n",
    "ax.set_xlim(-preperiod, postperiod/2)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.plot([0, 0.03], [-0.001, -0.001], color=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x192ae253b20>,\n",
       " <matplotlib.lines.Line2D at 0x192ae253b50>,\n",
       " <matplotlib.lines.Line2D at 0x192ae253c40>]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.plot(samples, average[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03055913, -0.03442416, -0.00556974,  1.33912469])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(62452,), (62361,), (62452,), (62452,)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.shape for t in times[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
