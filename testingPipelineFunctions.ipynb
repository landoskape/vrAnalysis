{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62912f35-2f40-4d93-872e-439919754adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "import vrExperiment as vre\n",
    "import vrFunctions as vrf\n",
    "import basicFunctions as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992ac1c1-0cd3-4f55-9759-6a9e312934ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Steps to code: \n",
    "# 1. consider replacing some of the functions in \"multiSessionAnalysis\"...\n",
    "# 2. add red cell processing functions into the pipeline\n",
    "\n",
    "# immediate goals: \n",
    "# 1. write functions for retrieving useful variables from oneData formats (e.g. speed, occupancy maps, etc.)\n",
    "# 2. do I save these? how long will it take to load? \n",
    "\n",
    "# BIG GOAL:\n",
    "# 1. Database time! Do this then rerun all your sessions\n",
    "# 2. Create smart loading system where each vrexp object loads one data into a floating dictionary, and every time something is needed it checks if it's loaded it and then loads it only when necessary\n",
    "#    For this to work, I'll have to exclusively use functions that are called on each vrexp object... it's a little tricky but I think it can work\n",
    "\n",
    "# -- before databasing, I want to test transformed data performance on a few sessions, i.e. I want to see how quickly I can regenerate key behavioral and neural variables from the onedata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b546e957-03cd-48ca-98e8-70c1db297f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In session: ATL022/2023-03-24/701, vrFile['rigInfo'] does not exist. Assuming default settings for B2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrew\\anaconda3\\envs\\vrAnalysis\\lib\\site-packages\\scipy\\stats\\_stats_py.py:2855: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = np.asanyarray(compare)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m701\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m vrReg \u001b[38;5;241m=\u001b[39m vre\u001b[38;5;241m.\u001b[39mvrExperimentRegistration(mouseName, dateString, session, oasis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, imaging\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mvrReg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoPreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m vrReg\u001b[38;5;241m.\u001b[39msaveParams()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(vrReg\u001b[38;5;241m.\u001b[39msessionPath())\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\vrAnalysis\\vrExperiment.py:201\u001b[0m, in \u001b[0;36mvrExperimentRegistration.doPreprocessing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdoPreprocessing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessTimeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessBehavior()\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessImaging()\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\vrAnalysis\\vrExperiment.py:251\u001b[0m, in \u001b[0;36mvrExperimentRegistration.processTimeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m refreshSamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39mrefreshRate\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mdiff(timestamps)))\n\u001b[0;32m    250\u001b[0m pdMedFilt \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mndimage\u001b[38;5;241m.\u001b[39mmedian_filter(pdDetrend,size\u001b[38;5;241m=\u001b[39mrefreshSamples)\n\u001b[1;32m--> 251\u001b[0m pdDerivative,pdDerivative \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfivePointDer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdMedFilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhfpd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturnIndex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m pdDerTime \u001b[38;5;241m=\u001b[39m timestamps[pdIndex]\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# find upward and downward peaks, not perfect but in practice close enough\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vrAnalysis\\lib\\site-packages\\scipy\\stats\\_stats_py.py:2713\u001b[0m, in \u001b[0;36mzscore\u001b[1;34m(a, axis, ddof, nan_policy)\u001b[0m\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzscore\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, nan_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpropagate\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   2645\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2646\u001b[0m \u001b[38;5;124;03m    Compute the z score.\u001b[39;00m\n\u001b[0;32m   2647\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2711\u001b[0m \u001b[38;5;124;03m           [-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])\u001b[39;00m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnan_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_policy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vrAnalysis\\lib\\site-packages\\scipy\\stats\\_stats_py.py:2872\u001b[0m, in \u001b[0;36mzmap\u001b[1;34m(scores, compare, axis, ddof, nan_policy)\u001b[0m\n\u001b[0;32m   2870\u001b[0m         isconst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(_isconst, axis, a)\n\u001b[0;32m   2871\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2872\u001b[0m     mn \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2873\u001b[0m     std \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39maxis, ddof\u001b[38;5;241m=\u001b[39mddof, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vrAnalysis\\lib\\site-packages\\numpy\\core\\_methods.py:180\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    177\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    182\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    183\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'slice'"
     ]
    }
   ],
   "source": [
    "# vrExperiment registration and preprocessing \n",
    "mouseName = 'ATL022'\n",
    "dateString = '2023-03-24'\n",
    "session = '701'\n",
    "vrReg = vre.vrExperimentRegistration(mouseName, dateString, session, oasis=False, imaging=True)\n",
    "vrReg.doPreprocessing()\n",
    "vrReg.saveParams()\n",
    "print(vrReg.sessionPath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bd1b233d-c46b-4a47-b3c7-ca90c4ac698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing summary variables\n",
    "# 1. convolve spks ==========================Note: I don't think I'm going to keep doing this. It barely changes the spike vector and we're already using GCaMP data anyway...\n",
    "# 2. occupancy map, speed map, lick map ================ finished\n",
    "# 3. spkmap for position (with spatial smoothing) =================== finished (and I wrote a toeplitz convolution that's fast)\n",
    "# 4. reliability measurements and spatial information measurements \n",
    "# 5. ROICaT alignment tools \n",
    "\n",
    "# create all these variables (make sure you did it correctly), and time how long it takes to load them\n",
    "# then save them all and time it takes how long to load them and how much data to save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4805af1-c76f-43ab-8e52-d013c2e89d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e43e9b6-b917-433c-a1a5-3064da5894f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mouseName = 'ATL022'\n",
    "dateString = '2023-03-24'\n",
    "session = '701'\n",
    "vrexp = vre.vrExperiment(mouseName, dateString, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7e2036c-4509-41bc-96ff-1d1337ffbb29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lick map should be included in 'getBehaviorMaps' eventually!\n",
      "CPU times: total: 13.5 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Retrieve smoothed and downsampled occupancymap and speedmap\n",
    "omap, smap, distvec = vrexp.getBehaviorMaps(speedThreshold=5) # produce smoothed occupancy and speed maps, along with the distance bins used to create them\n",
    "frameTrialIdx, framePosition, frameSpeed = vrexp.getFrameBehavior()\n",
    "spkmap = vrexp.getSpikeMap(frameTrialIdx, framePosition, frameSpeed, distvec, standardizeSpks=True, doSmoothing=5) # produce the spkmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28a11a32-6b91-4255-a223-65d3aa8d22e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 350 ms\n"
     ]
    }
   ],
   "source": [
    "%time mse, cor = measureReliability(spkmap, numcv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9847c2ce-b78b-45c3-949e-5c6ba0a869f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Next step: \n",
    "# integrate spatial reliability code into vrExperiment\n",
    "# Write code to measure spatial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d499ff9d-fe60-46cc-8f62-f6bf3960fe71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def vectorCorrelation(x,y):\n",
    "    # for each column in x, measure the correlation with each column in y\n",
    "    assert x.shape==y.shape, \"x and y need to have the same shape!\"\n",
    "    N = x.shape[0]\n",
    "    xDev = x - np.mean(x,axis=0)\n",
    "    yDev = y - np.mean(y,axis=0)\n",
    "    xSampleStd = np.sqrt(np.sum(xDev**2,axis=0)/(N-1))\n",
    "    ySampleStd = np.sqrt(np.sum(yDev**2,axis=0)/(N-1))\n",
    "    xStandard = xDev/xSampleStd\n",
    "    yStandard = yDev/ySampleStd\n",
    "    return np.sum(xStandard * yStandard,axis=0) / (N-1) \n",
    "\n",
    "def cvFoldSplit(numSamples, numFold):\n",
    "    minimumSamples = np.floor(numSamples / numFold)\n",
    "    remainder = numSamples - numFold*minimumSamples\n",
    "    samplesPerFold = [int(minimumSamples + 1*(f<remainder)) for f in range(numFold)]\n",
    "    sampleIdxPerFold = [0, *np.cumsum(samplesPerFold)]\n",
    "    randomOrder = np.random.permutation(numSamples)\n",
    "    foldIdx = [randomOrder[sampleIdxPerFold[i]:sampleIdxPerFold[i+1]] for i in range(numFold)]\n",
    "    return foldIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96601a-5182-4cd2-89b3-27d1a1585ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda3fb8-c80f-40f7-a5fd-4c86bf41493a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa5287-d350-48b5-9067-2fa0fd5f9437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e5c9a-ee19-4e27-949f-63d8c192da0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
