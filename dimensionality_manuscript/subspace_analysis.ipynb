{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab32d4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad docstring!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For the subspace analysis, we have three methods. PCA, cvPCA, and cross-covariance analysis.\n",
    "\n",
    "Each require the following:\n",
    "# A recipe to get train and test data\n",
    "# A recipe to get train place fields\n",
    "# A way to fit the components\n",
    "# And a way to measure the variance in the test data\n",
    "\n",
    "So using a similar structure to the ABC RegressionModel, I can probably define a core structure as follows:\n",
    "\n",
    "class SubspaceAnalysis:\n",
    "    def fit(self, session, spks_type): ... # Returns the fit components and extras (data, placefields, etc)\n",
    "    def score(self, session, fits, spks_type): ... # Returns the variance in the test data\n",
    "    def reconstruction_score(self, session, fits, spks_type): ... # Returns the frobenius norm of the difference between the test data and the reconstructed data for each expanding subspace\n",
    "    def get_scores(): ... # A similar cache method for getting scores without dealing with refitting which is slow\n",
    "\n",
    "Note that I'll also need hyperparameters for measuring the placefields.... unfortunately this isn't just a user choice\n",
    "because I should probably pick hyperparameters to maximize the variance the placefields explain in temporal data. \n",
    "\n",
    "But fortunately with some clever design I can build a structure that will \n",
    "allow me to make it easy to add or extend any one of the subspace methods. \n",
    "\"\"\"\n",
    "print('bad docstring!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79800b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from syd import make_viewer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vrAnalysis.database import get_database\n",
    "from vrAnalysis.helpers import Timer, get_placefield_location, cross_validate_trials, sort_by_preferred_environment\n",
    "from vrAnalysis.sessions import B2Session\n",
    "from vrAnalysis.processors import SpkmapProcessor\n",
    "from vrAnalysis.processors.support import median_zscore\n",
    "from vrAnalysis.processors.placefields import get_placefield, get_frame_behavior, get_placefield_prediction\n",
    "from dimilibi import Population\n",
    "from dimilibi import ReducedRankRegression, RidgeRegression\n",
    "from dimilibi import measure_r2, mse\n",
    "from dimilibi import PCA, SVCA\n",
    "from dimensionality_manuscript.registry import PopulationRegistry, get_subspace\n",
    "\n",
    "# get session database\n",
    "sessiondb = get_database(\"vrSessions\")\n",
    "\n",
    "# get population registry and models\n",
    "registry = PopulationRegistry()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e27e7ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de568fd690cf45f19b96e3f7571440ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optuna search:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_bins': 10, 'smooth_width': 16.267071394406756} 0.13626109063625336\n",
      "    num_bins  smooth_width           score\n",
      "0         53           NaN  tensor(0.3250)\n",
      "1         11      1.840899  tensor(0.1806)\n",
      "2         10     15.958574  tensor(0.1553)\n",
      "3         15      2.294868  tensor(0.2256)\n",
      "4         33           NaN  tensor(0.2929)\n",
      "5         13     10.952663  tensor(0.1699)\n",
      "6         28           NaN  tensor(0.2842)\n",
      "7         38      7.475993  tensor(0.2944)\n",
      "8         14           NaN  tensor(0.1963)\n",
      "9         93           NaN  tensor(0.2726)\n",
      "10        20     34.128905  tensor(0.2356)\n",
      "11        10     16.267071  tensor(0.1363)\n",
      "12        10     27.892316  tensor(0.1486)\n",
      "13        22     48.678687  tensor(0.2390)\n",
      "14        18     19.714910  tensor(0.2149)\n",
      "15        10     24.051990  tensor(0.1658)\n",
      "16        61      4.555236  tensor(0.2944)\n",
      "17        24     10.834234  tensor(0.2575)\n",
      "18        16      5.028560  tensor(0.2346)\n",
      "19        12     32.377885  tensor(0.1963)\n",
      "20        43     13.359750  tensor(0.2418)\n",
      "21        10     18.135077  tensor(0.1498)\n",
      "22        10     25.539105  tensor(0.1642)\n",
      "23        13     49.664247  tensor(0.1691)\n",
      "24        18      7.731683  tensor(0.2226)\n",
      "25        12     17.907872  tensor(0.1979)\n",
      "26        16           NaN  tensor(0.2279)\n",
      "27        10     31.241436  tensor(0.1611)\n",
      "28        27     12.720972  tensor(0.2296)\n",
      "29        63           NaN  tensor(0.2968)\n"
     ]
    }
   ],
   "source": [
    "submodel = get_subspace(\"pca_subspace\", registry)\n",
    "session = sessiondb.iter_sessions(imaging=True)[0]\n",
    "spks_type = \"oasis\"\n",
    "bprms, bscore, results = submodel._optimize_optuna(session, spks_type, \"train\", \"not_train\", n_trials=30)\n",
    "print(bprms, bscore)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2014bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2Session(mouse_name='ATL022', date='2023-05-03', session_id='701', spks_type='oasis')\n"
     ]
    }
   ],
   "source": [
    "# This code block runs the PCA version of the subspace analysis\n",
    "# It estimates the primary modes of variance using the train split for both the \n",
    "# full activity and the place fields. Then, it measures the variance within those\n",
    "# modes on the test split data - where we project the full activity in test on \n",
    "# either the PCs from the train full data or the PCs from the train place fields. \n",
    "\n",
    "session = random.choice(sessiondb.iter_sessions(imaging=True, session_params=dict(spks_type=\"oasis\")))\n",
    "print(session)\n",
    "\n",
    "center = False # don't think this matters much\n",
    "train_split = registry.time_split[\"half0\"]\n",
    "test_split = registry.time_split[\"half1\"]\n",
    "population, frame_behavior = registry.get_population(session, spks_type=\"oasis\")\n",
    "\n",
    "num_neurons = len(population.idx_neurons)\n",
    "train_data = population.apply_split(population.data[population.idx_neurons], train_split, prefiltered=False)\n",
    "test_data = population.apply_split(population.data[population.idx_neurons], test_split, prefiltered=False)\n",
    "frame_behavior_train = frame_behavior.filter(population.get_split_times(train_split, within_idx_samples=False))\n",
    "\n",
    "if center:\n",
    "    train_data = train_data - train_data.mean(dim=1, keepdim=True)\n",
    "    test_data = test_data - test_data.mean(dim=1, keepdim=True)\n",
    "\n",
    "num_bins = 100\n",
    "dist_edges = np.linspace(0, session.env_length[0], num_bins+1)\n",
    "placefield = get_placefield(\n",
    "    train_data.T.numpy(),\n",
    "    frame_behavior_train,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=5.0,\n",
    ")\n",
    "placefield_extended = torch.tensor(placefield.placefield).reshape(-1, num_neurons).T\n",
    "\n",
    "num_components = min(400, *train_data.shape, *test_data.shape, *placefield_extended.shape)\n",
    "pca_all = PCA(num_components=num_components).fit(train_data)\n",
    "pca_pos = PCA(num_components=num_components).fit(placefield_extended)  \n",
    "\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "components_all = pca_all.get_components().to(device)\n",
    "components_pos = pca_pos.get_components().to(device)\n",
    "train_variance_all = torch.var(train_data.T @ components_all, dim=0)\n",
    "test_variance_all = torch.var(test_data.T @ components_all, dim=0)\n",
    "train_variance_pos = torch.var(train_data.T @ components_pos, dim=0)\n",
    "test_variance_pos = torch.var(test_data.T @ components_pos, dim=0)\n",
    "\n",
    "# # Measure reconstruction error for expanding subspaces\n",
    "# reconstruction_error_all = torch.zeros(num_components)\n",
    "# reconstruction_error_pos = torch.zeros(num_components)\n",
    "# for i in tqdm(range(num_components)):\n",
    "#     c_comp_all = components_all[:, :i+1]\n",
    "#     c_comp_pos = components_pos[:, :i+1]\n",
    "#     recon_all = c_comp_all @ c_comp_all.T @ test_data\n",
    "#     recon_pos = c_comp_pos @ c_comp_pos.T @ test_data\n",
    "#     error_all = torch.norm(test_data - recon_all)\n",
    "#     error_pos = torch.norm(test_data - recon_pos)\n",
    "#     reconstruction_error_all[i] = error_all\n",
    "#     reconstruction_error_pos[i] = error_pos\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 8), layout=\"constrained\")\n",
    "ax[0, 0].plot(train_variance_all.cpu(), c='k')\n",
    "ax[0, 0].plot(test_variance_all.cpu(), c='b')\n",
    "ax[0, 0].set_title(\"Comparing Train vs Test Full\\nVariance\")\n",
    "ax[1, 0].plot(torch.cumsum(train_variance_all.cpu(), dim=0), c='k')\n",
    "ax[1, 0].plot(torch.cumsum(test_variance_all.cpu(), dim=0), c='b')\n",
    "ax[1, 0].set_title(\"Cumulative variance\")\n",
    "ax[2, 0].plot(torch.cumsum(test_variance_all.cpu(), dim=0) / torch.cumsum(train_variance_all.cpu(), dim=0), c='b')\n",
    "ax[2, 0].set_title(\"Subspace Ratio\")\n",
    "\n",
    "ax[0, 1].plot(test_variance_all.cpu(), c='b')\n",
    "ax[0, 1].plot(test_variance_pos.cpu(), c='g')\n",
    "ax[0, 1].set_title(\"Comparing Test Full vs Test Placefields\\nVariance\")\n",
    "ax[1, 1].plot(torch.cumsum(test_variance_all.cpu(), dim=0), c='b')\n",
    "ax[1, 1].plot(torch.cumsum(test_variance_pos.cpu(), dim=0), c='g')\n",
    "ax[1, 1].set_title(\"Cumulative variance\")\n",
    "ax[2, 1].plot(torch.cumsum(test_variance_pos.cpu(), dim=0) / torch.cumsum(test_variance_all.cpu(), dim=0), c='g')\n",
    "ax[2, 1].set_title(\"Subspace Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca3d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2Session(mouse_name='ATL020', date='2023-04-11', session_id='701', spks_type='oasis')\n",
      "torch.Size([7860, 3448]) torch.Size([7860, 3448]) torch.Size([7860, 1725]) torch.Size([7860, 200]) torch.Size([7860, 200])\n"
     ]
    }
   ],
   "source": [
    "# This code block runs the cv PCA version of the subspace analysis\n",
    "session = random.choice(sessiondb.iter_sessions(imaging=True, session_params=dict(spks_type=\"oasis\")))\n",
    "print(session)\n",
    "\n",
    "train0_split = registry.time_split[\"train0\"]\n",
    "train1_split = registry.time_split[\"train1\"]\n",
    "test_split = registry.time_split[\"not_train\"]\n",
    "population, frame_behavior = registry.get_population(session, spks_type=\"oasis\")\n",
    "\n",
    "num_neurons = len(population.idx_neurons)\n",
    "train0_data = population.apply_split(population.data[population.idx_neurons], train0_split, prefiltered=False)\n",
    "train1_data = population.apply_split(population.data[population.idx_neurons], train1_split, prefiltered=False)\n",
    "test_data = population.apply_split(population.data[population.idx_neurons], test_split, prefiltered=False)\n",
    "frame_behavior_train0 = frame_behavior.filter(population.get_split_times(train0_split, within_idx_samples=False))\n",
    "frame_behavior_train1 = frame_behavior.filter(population.get_split_times(train1_split, within_idx_samples=False))\n",
    "\n",
    "if train0_data.shape[1] != train1_data.shape[1]:\n",
    "    num_samples = min(train0_data.shape[1], train1_data.shape[1])\n",
    "    idx_train0 = np.sort(np.random.choice(train0_data.shape[1], num_samples, replace=False))\n",
    "    idx_train1 = np.sort(np.random.choice(train1_data.shape[1], num_samples, replace=False))\n",
    "    train0_data = train0_data[:, idx_train0]\n",
    "    train1_data = train1_data[:, idx_train1]\n",
    "    frame_behavior_train0 = frame_behavior_train0.filter(idx_train0)\n",
    "    frame_behavior_train1 = frame_behavior_train1.filter(idx_train1)\n",
    "\n",
    "num_bins = 100\n",
    "dist_edges = np.linspace(0, session.env_length[0], num_bins+1)\n",
    "placefield0 = get_placefield(\n",
    "    train0_data.T.numpy(),\n",
    "    frame_behavior_train0,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=5.0,\n",
    ")\n",
    "placefield1 = get_placefield(\n",
    "    train1_data.T.numpy(),\n",
    "    frame_behavior_train1,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=5.0,\n",
    ")\n",
    "placefield0_extended = torch.tensor(placefield0.placefield).reshape(-1, num_neurons).T\n",
    "placefield1_extended = torch.tensor(placefield1.placefield).reshape(-1, num_neurons).T\n",
    "\n",
    "num_components = min(400, *train0_data.shape, *train1_data.shape, *test_data.shape, *placefield0_extended.shape, *placefield1_extended.shape)\n",
    "\n",
    "centered = True\n",
    "svca_all = SVCA(centered=centered, num_components=num_components)\n",
    "svca_all = svca_all.fit(train0_data, train1_data)\n",
    "svca_pos = SVCA(centered=centered, num_components=num_components)\n",
    "svca_pos = svca_pos.fit(placefield0_extended, placefield1_extended)\n",
    "\n",
    "components_all = svca_all.U\n",
    "components_pos = svca_pos.U\n",
    "train_variance_all = torch.var(train_data.T @ components_all, dim=0)\n",
    "test_variance_all = torch.var(test_data.T @ components_all, dim=0)\n",
    "train_variance_pos = torch.var(train_data.T @ components_pos, dim=0)\n",
    "test_variance_pos = torch.var(test_data.T @ components_pos, dim=0)\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 8), layout=\"constrained\")\n",
    "ax[0, 0].plot(train_variance_all, c='k')\n",
    "ax[0, 0].plot(test_variance_all, c='b')\n",
    "ax[0, 0].set_title(\"Comparing Train vs Test Full\\nVariance\")\n",
    "ax[1, 0].plot(torch.cumsum(train_variance_all, dim=0), c='k')\n",
    "ax[1, 0].plot(torch.cumsum(test_variance_all, dim=0), c='b')\n",
    "ax[1, 0].set_title(\"Cumulative variance\")\n",
    "ax[2, 0].plot(torch.cumsum(test_variance_all, dim=0) / torch.cumsum(train_variance_all, dim=0), c='b')\n",
    "ax[2, 0].set_title(\"Subspace Ratio\")\n",
    "\n",
    "ax[0, 1].plot(test_variance_all, c='b')\n",
    "ax[0, 1].plot(test_variance_pos, c='g')\n",
    "ax[0, 1].set_title(\"Comparing Test Full vs Test Placefields\\nVariance\")\n",
    "ax[1, 1].plot(torch.cumsum(test_variance_all, dim=0), c='b')\n",
    "ax[1, 1].plot(torch.cumsum(test_variance_pos, dim=0), c='g')\n",
    "ax[1, 1].set_title(\"Cumulative variance\")\n",
    "ax[2, 1].plot(torch.cumsum(test_variance_pos, dim=0) / torch.cumsum(test_variance_all, dim=0), c='g')\n",
    "ax[2, 1].set_title(\"Subspace Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2461df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_all = svca_all.U\n",
    "components_pos = svca_pos.U\n",
    "train_variance_all = torch.var(train0_data.T @ components_all, dim=0)\n",
    "test_variance_all = torch.var(test_data.T @ components_all, dim=0)\n",
    "train_variance_pos = torch.var(train0_data.T @ components_pos, dim=0)\n",
    "test_variance_pos = torch.var(test_data.T @ components_pos, dim=0)\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 8), layout=\"constrained\")\n",
    "ax[0, 0].plot(train_variance_all, c='k')\n",
    "ax[0, 0].plot(test_variance_all, c='b')\n",
    "ax[0, 0].set_title(\"Comparing Train vs Test Full\\nVariance\")\n",
    "ax[1, 0].plot(torch.cumsum(train_variance_all, dim=0), c='k')\n",
    "ax[1, 0].plot(torch.cumsum(test_variance_all, dim=0), c='b')\n",
    "ax[1, 0].set_title(\"Cumulative variance\")\n",
    "ax[2, 0].plot(torch.cumsum(test_variance_all, dim=0) / torch.cumsum(train_variance_all, dim=0), c='b')\n",
    "ax[2, 0].set_title(\"Subspace Ratio\")\n",
    "\n",
    "ax[0, 1].plot(test_variance_all, c='b')\n",
    "ax[0, 1].plot(test_variance_pos, c='g')\n",
    "ax[0, 1].set_title(\"Comparing Test Full vs Test Placefields\\nVariance\")\n",
    "ax[1, 1].plot(torch.cumsum(test_variance_all, dim=0), c='b')\n",
    "ax[1, 1].plot(torch.cumsum(test_variance_pos, dim=0), c='g')\n",
    "ax[1, 1].set_title(\"Cumulative variance\")\n",
    "ax[2, 1].plot(torch.cumsum(test_variance_pos, dim=0) / torch.cumsum(test_variance_all, dim=0), c='g')\n",
    "ax[2, 1].set_title(\"Subspace Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1dcc6b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2Session(mouse_name='ATL058', date='2024-07-18', session_id='701', spks_type='oasis')\n"
     ]
    }
   ],
   "source": [
    "# This code block runs the SVCA version of the subspace analysis\n",
    "\n",
    "session = random.choice(sessiondb.iter_sessions(imaging=True, session_params=dict(spks_type=\"oasis\")))\n",
    "print(session)\n",
    "\n",
    "train_split = registry.time_split[\"half0\"]\n",
    "test_split = registry.time_split[\"half1\"]\n",
    "population, frame_behavior = registry.get_population(session, spks_type=\"oasis\")\n",
    "\n",
    "num_source_neurons = len(population.cell_split_indices[0])\n",
    "num_target_neurons = len(population.cell_split_indices[1])\n",
    "train_source, train_target = population.get_split_data(train_split)\n",
    "test_source, test_target = population.get_split_data(test_split)\n",
    "frame_behavior_train = frame_behavior.filter(population.get_split_times(train_split, within_idx_samples=False))\n",
    "\n",
    "num_bins = 100\n",
    "dist_edges = np.linspace(0, session.env_length[0], num_bins+1)\n",
    "placefield_source = get_placefield(\n",
    "    train_source.T.numpy(),\n",
    "    frame_behavior_train,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=5.0,\n",
    ")\n",
    "placefield_target = get_placefield(\n",
    "    train_target.T.numpy(),\n",
    "    frame_behavior_train,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=5.0,\n",
    ")\n",
    "placefield_source_extended = torch.tensor(placefield_source.placefield).reshape(-1, num_source_neurons).T\n",
    "placefield_target_extended = torch.tensor(placefield_target.placefield).reshape(-1, num_target_neurons).T\n",
    "\n",
    "num_components = min(*train_source.shape, *train_target.shape, *placefield_source_extended.shape, *placefield_target_extended.shape)\n",
    "\n",
    "centered = True\n",
    "svca_all = SVCA(centered=centered, num_components=num_components)\n",
    "svca_all = svca_all.fit(train_source, train_target)\n",
    "svca_pos = SVCA(centered=centered, num_components=num_components)\n",
    "svca_pos = svca_pos.fit(placefield_source_extended, placefield_target_extended)\n",
    "\n",
    "sv_all_train = svca_all.score(train_source, train_target)[0]\n",
    "sv_all_test = svca_all.score(test_source, test_target)[0]\n",
    "sv_pos_train = svca_pos.score(train_source, train_target)[0]\n",
    "sv_pos_test = svca_pos.score(test_source, test_target)[0]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 8), layout=\"constrained\")\n",
    "ax[0, 0].plot(sv_all_train, c='k')\n",
    "ax[0, 0].plot(sv_all_test, c='b')\n",
    "ax[0, 0].set_title(\"Comparing Train vs Test Full\\nVariance\")\n",
    "ax[1, 0].plot(torch.cumsum(sv_all_train, dim=0), c='k')\n",
    "ax[1, 0].plot(torch.cumsum(sv_all_test, dim=0), c='b')\n",
    "ax[1, 0].set_title(\"Cumulative variance\")\n",
    "ax[2, 0].plot(torch.cumsum(sv_all_test, dim=0) / torch.cumsum(sv_all_train, dim=0), c='b')\n",
    "ax[2, 0].set_title(\"Subspace Ratio\")\n",
    "\n",
    "ax[0, 1].plot(sv_all_test, c='b')\n",
    "ax[0, 1].plot(sv_pos_test, c='g')\n",
    "ax[0, 1].set_title(\"Comparing Test Full vs Test Placefields\\nVariance\")\n",
    "ax[1, 1].plot(torch.cumsum(sv_all_test, dim=0), c='b')\n",
    "ax[1, 1].plot(torch.cumsum(sv_pos_test, dim=0), c='g')\n",
    "ax[1, 1].set_title(\"Cumulative variance\")\n",
    "ax[2, 1].plot(torch.cumsum(sv_pos_test, dim=0) / torch.cumsum(sv_all_test, dim=0), c='g')\n",
    "ax[2, 1].set_title(\"Subspace Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa43b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee3917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block runs a simulation for how the PCA version of the subspace analysis will work if \n",
    "# the train and test data are generated from slightly different subspaces. \n",
    "\n",
    "num_samples = 100000\n",
    "num_neurons = 100\n",
    "num_components = 100\n",
    "\n",
    "# Generate eigenspectrum\n",
    "eigenvalues = 1.2 ** -torch.arange(num_components)\n",
    "same_fraction = 0.5\n",
    "_ev_shared = torch.randn(num_neurons, num_neurons)\n",
    "eigenvectors_train = torch.linalg.qr(same_fraction * _ev_shared + (1-same_fraction) * torch.randn(num_neurons, num_neurons)).Q[:, :num_components]\n",
    "eigenvectors_test = torch.linalg.qr(same_fraction * _ev_shared + (1-same_fraction) * torch.randn(num_neurons, num_neurons)).Q[:, :num_components]\n",
    "\n",
    "# Generate random data\n",
    "train_data = eigenvectors_train @ torch.diag(torch.sqrt(eigenvalues)) @ torch.randn(num_components, num_samples)\n",
    "test_data = eigenvectors_test @ torch.diag(torch.sqrt(eigenvalues)) @ torch.randn(num_components, num_samples)\n",
    "\n",
    "# Measure the eigenspectrum of the data\n",
    "train_data_cov = train_data @ train_data.T / num_samples\n",
    "eigenvalues_train, _ = torch.linalg.eigh(train_data_cov)\n",
    "eigenvalues_train = torch.flip(eigenvalues_train, dims=(0,))\n",
    "\n",
    "# Plot eigenspectrum\n",
    "plt.close('all')\n",
    "plt.plot(eigenvalues, c='k')\n",
    "plt.plot(eigenvalues_train, c='b')\n",
    "plt.show()\n",
    "\n",
    "# Now run PCA on train data and measure total variance in each expanding subspace of test data\n",
    "train_pca = PCA(num_components=num_components).fit(train_data)\n",
    "\n",
    "# Then go and measure the total variance in each expanding subspace of test data\n",
    "components = train_pca.get_components()\n",
    "cv_variance = torch.zeros(num_components)\n",
    "exp_variance = torch.zeros(num_components)\n",
    "for i in tqdm(range(num_components)):\n",
    "    exp_variance[i] = torch.var(components[:, :i+1].T @ train_data, dim=1).sum()\n",
    "    cv_variance[i] = torch.var(components[:, :i+1].T @ test_data, dim=1).sum()\n",
    "    \n",
    "# If the subspaces differ, the blue curve should take a while to catch up to the black curve. \n",
    "plt.close('all')\n",
    "plt.plot(exp_variance+2, c='k')\n",
    "plt.plot(cv_variance+2, c='b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
