{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the subspace analysis, we have three methods. PCA, cvPCA, and cross-covariance analysis.\n",
    "\n",
    "Each require the following:\n",
    "# A recipe to get train and test data\n",
    "# A recipe to get train place fields\n",
    "# A way to fit the components\n",
    "# And a way to measure the variance in the test data\n",
    "\n",
    "So using a similar structure to the ABC RegressionModel, I can probably define a core structure as follows:\n",
    "\n",
    "class SubspaceAnalysis:\n",
    "    def fit(self, session, spks_type): ... # Returns the fit components and extras (data, placefields, etc)\n",
    "    def score(self, session, fits, spks_type): ... # Returns the variance in the test data\n",
    "    def reconstruction_score(self, session, fits, spks_type): ... # Returns the frobenius norm of the difference between the test data and the reconstructed data for each expanding subspace\n",
    "    def get_scores(): ... # A similar cache method for getting scores without dealing with refitting which is slow\n",
    "\n",
    "Note that I'll also need hyperparameters for measuring the placefields.... unfortunately this isn't just a user choice\n",
    "because I should probably pick hyperparameters to maximize the variance the placefields explain in temporal data. \n",
    "\n",
    "But fortunately with some clever design I can build a structure that will \n",
    "allow me to make it easy to add or extend any one of the subspace methods. \n",
    "\"\"\"\n",
    "print('bad docstring!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79800b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from matplotlib import pyplot as plt\n",
    "from syd import make_viewer, Viewer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vrAnalysis.database import get_database\n",
    "from vrAnalysis.helpers import Timer, format_spines, beeswarm, errorPlot, save_figure\n",
    "from vrAnalysis.processors.placefields import get_placefield\n",
    "from dimilibi import PCA, SVCA\n",
    "from dimensionality_manuscript.registry import PopulationRegistry, get_subspace, SubspaceName\n",
    "from dimensionality_manuscript.subspace_analysis.base import Subspace\n",
    "from dimensionality_manuscript.regression_models.hyperparameters import PlaceFieldHyperparameters\n",
    "from dimensionality_manuscript.simulations import sqrtm_spd\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "# get session database\n",
    "sessiondb = get_database(\"vrSessions\")\n",
    "\n",
    "# get population registry and models\n",
    "registry = PopulationRegistry()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSPACE_NAMES: list[SubspaceName] = [\n",
    "    \"pca_subspace\",\n",
    "    # \"cvpca_subspace\",\n",
    "    # \"svca_subspace\",\n",
    "    \"covcov_subspace\",\n",
    "    \"covcov_crossvalidated_subspace\"\n",
    "]\n",
    "subspaces = [get_subspace(name, registry) for name in SUBSPACE_NAMES]\n",
    "spks_type = \"oasis\"\n",
    "sessiondb = get_database(\"vrSessions\")\n",
    "registry = PopulationRegistry()\n",
    "\n",
    "specific_hyperparameters = PlaceFieldHyperparameters(num_bins=100, smooth_width=None)\n",
    "\n",
    "num_sessions = len(sessiondb.iter_sessions(imaging=True))\n",
    "mouse_names = []\n",
    "model_metrics = [[] for _ in subspaces]\n",
    "for isession, session in enumerate(tqdm(sessiondb.iter_sessions(imaging=True, session_params=dict(spks_type=spks_type)))):\n",
    "    mouse_names.append(session.mouse_name)\n",
    "    for imodel, model in enumerate(subspaces):        \n",
    "        metrics = model.get_score(session, spks_type=spks_type, hyperparameters=specific_hyperparameters)\n",
    "        model_metrics[imodel].append(metrics)\n",
    "mouse_names = np.array(mouse_names)\n",
    "\n",
    "score = np.full((len(subspaces), len(mouse_names)), np.nan)\n",
    "varact, varpos = [], []\n",
    "for i in range(len(subspaces)):\n",
    "    c_scores = np.array([m[\"evaluation_score\"] for m in model_metrics[i]])\n",
    "    c_varact = [m[\"variance_activity\"] for m in model_metrics[i]]\n",
    "    c_varpos = [m[\"variance_placefields\"] for m in model_metrics[i]]\n",
    "    score[i] = c_scores\n",
    "    varact.append(c_varact)\n",
    "    varpos.append(c_varpos)\n",
    "\n",
    "num_envs = 3\n",
    "max_dims = max([len(v) for v in varact[0]+varact[1]])\n",
    "varact_pad = np.full((len(subspaces), num_envs, len(mouse_names), max_dims), np.nan)\n",
    "varpos_pad = np.full((len(subspaces), num_envs, len(mouse_names), max_dims), np.nan)\n",
    "for i in range(len(subspaces)):\n",
    "    for j in range(len(mouse_names)):\n",
    "        num_dims = len(varact[i][j])\n",
    "        idx_env = int(num_dims // 100) - 1\n",
    "        varact_pad[i, idx_env, j, :len(varact[i][j])] = varact[i][j]\n",
    "        varpos_pad[i, idx_env, j, :len(varpos[i][j])] = varpos[i][j]\n",
    "\n",
    "mice = list(set(mouse_names))\n",
    "avg_scores = np.full((len(SUBSPACE_NAMES), len(mice)), np.nan)\n",
    "avg_varact = np.full((len(SUBSPACE_NAMES), num_envs, len(mice), max_dims), np.nan)\n",
    "avg_varpos = np.full((len(SUBSPACE_NAMES), num_envs, len(mice), max_dims), np.nan)\n",
    "for imodel, model_name in enumerate(SUBSPACE_NAMES):\n",
    "    for imouse, mouse in enumerate(mice):\n",
    "        if np.sum(mouse_names == mouse) == 0:\n",
    "            print(f\"No sessions for {mouse} with model {model_name}\")\n",
    "        avg_scores[imodel, imouse] = np.mean(score[imodel][mouse_names == mouse])\n",
    "        avg_varact[imodel, :, imouse] = np.nanmean(varact_pad[imodel][:, mouse_names == mouse], axis=1)\n",
    "        avg_varpos[imodel, :, imouse] = np.nanmean(varpos_pad[imodel][:, mouse_names == mouse], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51903cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxmodel0 = 1\n",
    "idxmodel1 = 2\n",
    "\n",
    "class SubspaceViewer(Viewer):\n",
    "    def __init__(self):\n",
    "        self.add_integer(\"idx_mouse\", min=0, max=len(mice)-1)\n",
    "        self.add_integer(\"num_envs\", min=1, max=num_envs)\n",
    "        self.add_selection(\"plot_type\", options=[\"both\", \"difference\"])\n",
    "        self.add_selection(\"data_type\", options=[\"cumvariance\", \"variance\"])\n",
    "        self.add_selection(\"xscale\", options=[\"linear\", \"log\"])\n",
    "        self.add_selection(\"yscale\", options=[\"linear\", \"log\"])\n",
    "        self.add_boolean(\"normalize\", value=True)\n",
    "        self.add_boolean(\"all\", value=True)\n",
    "\n",
    "    def plot(self, state):\n",
    "        idx_env = state[\"num_envs\"] - 1\n",
    "        if state[\"all\"]:\n",
    "            data_activity = avg_varact[:, idx_env]\n",
    "            data_placefields = avg_varpos[:, idx_env]\n",
    "            if state[\"normalize\"]:\n",
    "                total_variance = np.nansum(data_activity, axis=2, keepdims=True)\n",
    "                data_activity = data_activity / total_variance\n",
    "                data_placefields = data_placefields / total_variance\n",
    "            if state[\"data_type\"] == \"cumvariance\":\n",
    "                data_activity = np.cumsum(data_activity, axis=2)\n",
    "                data_placefields = np.cumsum(data_placefields, axis=2)\n",
    "                \n",
    "        else:\n",
    "            idx_mouse = state[\"idx_mouse\"]\n",
    "            data_activity = avg_varact[:, idx_env, idx_mouse]\n",
    "            data_placefields = avg_varpos[:, idx_env, idx_mouse]\n",
    "            if state[\"normalize\"]:\n",
    "                total_variance = np.nansum(data_activity, axis=1, keepdims=True)\n",
    "                data_activity = data_activity / total_variance\n",
    "                data_placefields = data_placefields / total_variance\n",
    "\n",
    "            if state[\"data_type\"] == \"cumvariance\":\n",
    "                data_activity = np.cumsum(data_activity, axis=1)\n",
    "                data_placefields = np.cumsum(data_placefields, axis=1)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 4), layout=\"constrained\", sharey=True, sharex=True)\n",
    "        if state[\"all\"]:\n",
    "            if state[\"plot_type\"] == \"difference\":\n",
    "                difference = data_activity - data_placefields\n",
    "                ax[0].plot(range(1, max_dims+1), difference[idxmodel0].T, color=\"k\", alpha=0.25)\n",
    "                ax[1].plot(range(1, max_dims+1), difference[idxmodel1].T, color=\"k\", alpha=0.25)\n",
    "                ax[0].plot(range(1, max_dims+1), np.nanmean(difference[idxmodel0], axis=0), color=\"k\")\n",
    "                ax[1].plot(range(1, max_dims+1), np.nanmean(difference[idxmodel1], axis=0), color=\"k\")\n",
    "            elif state[\"plot_type\"] == \"both\":\n",
    "                ax[0].plot(range(1, max_dims+1), data_activity[idxmodel0].T, color=\"k\", alpha=0.25)\n",
    "                ax[0].plot(range(1, max_dims+1), data_placefields[idxmodel0].T, color=\"b\", alpha=0.25)\n",
    "                ax[1].plot(range(1, max_dims+1), data_activity[idxmodel1].T, color=\"k\", alpha=0.25)\n",
    "                ax[1].plot(range(1, max_dims+1), data_placefields[idxmodel1].T, color=\"b\", alpha=0.25)\n",
    "\n",
    "                ax[0].plot(range(1, max_dims+1), np.nanmean(data_activity[idxmodel0], axis=0), color=\"k\", label=\"Activity\")\n",
    "                ax[0].plot(range(1, max_dims+1), np.nanmean(data_placefields[idxmodel0], axis=0), color=\"b\", label=\"Placefields\")\n",
    "                ax[1].plot(range(1, max_dims+1), np.nanmean(data_activity[idxmodel1], axis=0), color=\"k\", label=\"Activity\")\n",
    "                ax[1].plot(range(1, max_dims+1), np.nanmean(data_placefields[idxmodel1], axis=0), color=\"b\", label=\"Placefields\")\n",
    "\n",
    "                ax[0].set_title(f\"{np.nansum(data_activity[idxmodel0])}\")\n",
    "                ax[1].set_title(f\"{np.nansum(data_activity[idxmodel1])}\")\n",
    "                ax[0].legend(fontsize=12, loc=\"best\")\n",
    "                ax[1].legend(fontsize=12, loc=\"best\")\n",
    "        else:\n",
    "            if state[\"plot_type\"] == \"difference\":\n",
    "                ax[0].plot(range(1, max_dims+1), data_activity[idxmodel0] - data_placefields[idxmodel0], color=\"k\")\n",
    "                ax[1].plot(range(1, max_dims+1), data_activity[idxmodel1] - data_placefields[idxmodel1], color=\"k\")\n",
    "            elif state[\"plot_type\"] == \"both\":\n",
    "                ax[0].plot(range(1, max_dims+1), data_activity[idxmodel0], color=\"k\", label=\"Activity\")\n",
    "                ax[0].plot(range(1, max_dims+1), data_placefields[idxmodel0], color=\"b\", label=\"Placefields\")\n",
    "                ax[1].plot(range(1, max_dims+1), data_activity[idxmodel1], color=\"k\", label=\"Activity\")\n",
    "                ax[1].plot(range(1, max_dims+1), data_placefields[idxmodel1], color=\"b\", label=\"Placefields\")\n",
    "                ax[0].set_title(f\"{np.nansum(data_activity[idxmodel0])}\")\n",
    "                ax[1].set_title(f\"{np.nansum(data_activity[idxmodel1])}\")\n",
    "\n",
    "                if state[\"data_type\"] == \"variance\":\n",
    "                    xneg_activity_0 = np.where(data_activity[idxmodel0] < 0)[0]\n",
    "                    xneg_activity_1 = np.where(data_activity[idxmodel1] < 0)[0]\n",
    "                    xneg_placefields_0 = np.where(data_placefields[idxmodel0] < 0)[0]\n",
    "                    xneg_placefields_1 = np.where(data_placefields[idxmodel1] < 0)[0]\n",
    "                    ax[0].scatter(xneg_activity_0, -0.005*np.ones(len(xneg_activity_0)), color=\"k\", s=8, alpha=0.3)\n",
    "                    ax[0].scatter(xneg_placefields_0, -0.010*np.ones(len(xneg_placefields_0)), color=\"b\", s=8, alpha=0.3)\n",
    "                    ax[1].scatter(xneg_activity_1, -0.005*np.ones(len(xneg_activity_1)), color=\"k\", s=8, alpha=0.3)\n",
    "                    ax[1].scatter(xneg_placefields_1, -0.010*np.ones(len(xneg_placefields_1)), color=\"b\", s=8, alpha=0.3)\n",
    "\n",
    "                ax[0].legend(fontsize=12, loc=\"best\")\n",
    "                ax[1].legend(fontsize=12, loc=\"best\")\n",
    "        ax[0].set_xscale(state[\"xscale\"])\n",
    "        ax[1].set_xscale(state[\"xscale\"])\n",
    "        ax[0].set_yscale(state[\"yscale\"])\n",
    "        ax[1].set_yscale(state[\"yscale\"])\n",
    "\n",
    "        ax[0].set_title(\"Cov-Cov\")\n",
    "        ax[1].set_title(\"Cross-Validated!\")\n",
    "        return fig\n",
    "\n",
    "viewer = SubspaceViewer()\n",
    "viewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance = np.nansum(avg_varact, axis=3, keepdims=True)\n",
    "norm_data_activity = avg_varact / total_variance\n",
    "norm_data_placefields = avg_varpos / total_variance\n",
    "\n",
    "csnorm_data_activity = np.cumsum(norm_data_activity, axis=3)\n",
    "csnorm_data_placefields = np.cumsum(norm_data_placefields, axis=3)\n",
    "\n",
    "\n",
    "idx_model = 2 # Use the COVCOV model\n",
    "idx_mouse = 6\n",
    "beewidth = 0.2\n",
    "full_color = \"black\"\n",
    "placefield_color = \"orange\"\n",
    "        \n",
    "xlim = (0, max_dims+1)\n",
    "ylim = (5e-5, 2e-1)\n",
    "xticks = [0, 100, 200, 300]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 4), width_ratios=[2, 2, 1], layout=\"constrained\")\n",
    "need_label = True\n",
    "for inumenv in [2]:\n",
    "    if np.any(np.isnan(norm_data_activity[idx_model, inumenv, idx_mouse])):\n",
    "        print(f\"NaN values in norm_data_activity for model {idx_model}, env {inumenv}, mouse {idx_mouse}\")\n",
    "    if np.any(np.isnan(norm_data_placefields[idx_model, inumenv, idx_mouse])):\n",
    "        print(f\"NaN values in norm_data_placefields for model {idx_model}, env {inumenv}, mouse {idx_mouse}\")\n",
    "    ax[0].plot(range(1, max_dims+1), norm_data_activity[idx_model, inumenv, idx_mouse].T, color=full_color, label=\"Full\" if need_label else None)\n",
    "    ax[0].plot(range(1, max_dims+1), norm_data_placefields[idx_model, inumenv, idx_mouse].T, color=placefield_color, label=\"PFs\" if need_label else None)\n",
    "    need_label = False\n",
    "ax[0].set_xlabel(\"Dimension\")\n",
    "ax[0].set_ylabel(\"Variance\")\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "ax[0].set_title(\"Example Mouse\")\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlim(xlim)\n",
    "ax[0].set_ylim(ylim)\n",
    "format_spines(ax[0], x_pos=-0.02, y_pos=-0.02, xbounds=xlim, xticks=xticks, ybounds=ylim)\n",
    "\n",
    "\n",
    "ylim = (0, 1)\n",
    "need_label = True\n",
    "for inumenv in [0, 2]:\n",
    "    errorPlot(range(1, max_dims+1), csnorm_data_activity[idx_model, inumenv], axis=0, ax=ax[1], se=False, color=full_color, label=\"Full\" if need_label else None, alpha=0.1)\n",
    "    errorPlot(range(1, max_dims+1), csnorm_data_placefields[idx_model, inumenv], axis=0, ax=ax[1], se=False, color=placefield_color, label=\"PFs\" if need_label else None, alpha=0.1)\n",
    "    need_label = False\n",
    "ax[1].set_xlabel(\"Dimension\")\n",
    "ax[1].set_ylabel(\"Cum. Variance\")\n",
    "ax[1].legend(loc=\"lower right\")\n",
    "ax[1].set_title(\"Across Mice\")\n",
    "format_spines(ax[1], x_pos=-0.02, y_pos=-0.02, xbounds=xlim, xticks=xticks, ybounds=ylim, yticks=ylim)\n",
    "\n",
    "show_envs = [0, 1, 2]\n",
    "xbounds = (0, len(show_envs)-1)\n",
    "xlim = (-0.5, len(show_envs)-0.5)\n",
    "ylim = (0, 1)\n",
    "for ii, idx in enumerate(show_envs):\n",
    "    ilast = (idx + 1) * 100 - 1\n",
    "    c_data_activity = csnorm_data_activity[idx_model, idx, :, ilast - 1]\n",
    "    c_data_placefields = csnorm_data_placefields[idx_model, idx, :, ilast - 1]\n",
    "    c_fraction = c_data_placefields / c_data_activity\n",
    "    c_valid_fraction = c_fraction[~np.isnan(c_fraction)]\n",
    "    print(np.mean(c_valid_fraction))\n",
    "    ax[2].plot(ii + beewidth*beeswarm(c_valid_fraction), c_valid_fraction, color=full_color, marker=\".\", linestyle=\"none\", label=\"Full\")\n",
    "ax[2].set_xlim(xlim)\n",
    "ax[2].set_ylim(ylim)\n",
    "ax[2].set_xlabel(\"Num Envs\")\n",
    "ax[2].set_ylabel(\"Fractional Variance\")\n",
    "format_spines(ax[2], x_pos=-0.02, y_pos=-0.02, xbounds=xbounds, ybounds=ylim)\n",
    "ax[2].set_xticks(range(len(show_envs)))\n",
    "ax[2].set_xticklabels([f\"{idx + 1}\" for idx in show_envs])\n",
    "ax[2].set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "ax[2].set_yticklabels([0, '', '', '', 1])\n",
    "\n",
    "model_name = {\n",
    "    0: \"pca\",\n",
    "    1: \"covcov\",\n",
    "    2: \"covcov_correlation\",\n",
    "}\n",
    "figure_path = registry.registry_paths.figure_path / \"subspace_analysis\" / f\"{model_name[idx_model]}_subspace_basic_figure\"\n",
    "# save_figure(fig, figure_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c28a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance = np.nansum(avg_varact, axis=3, keepdims=True)\n",
    "norm_data_activity = avg_varact / total_variance\n",
    "norm_data_placefields = avg_varpos / total_variance\n",
    "\n",
    "csnorm_data_activity = np.cumsum(norm_data_activity, axis=3)\n",
    "csnorm_data_placefields = np.cumsum(norm_data_placefields, axis=3)\n",
    "\n",
    "\n",
    "idx_model_0 = 1\n",
    "idx_model_1 = 2\n",
    "reference_color = \"black\"\n",
    "color_model = [\"orange\", \"blue\"]\n",
    "linestyle_model = [\"solid\", \"dashed\"]\n",
    "model_label = [\"PF-Cov\", \"PF-Norm\"]\n",
    "idx_mouse = 6\n",
    "beewidth = 0.2\n",
    "        \n",
    "xlim = (0, max_dims+1)\n",
    "ylim = (1e-5, 1e-1)\n",
    "xticks = [0, 100, 200, 300]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 4), width_ratios=[2, 2, 1], layout=\"constrained\")\n",
    "for imodel, idx_model in enumerate([idx_model_0, idx_model_1]):\n",
    "    full_label = \"Full\" if imodel == 0 else None\n",
    "    pf_label = model_label[imodel]\n",
    "    for inumenv in [2]:\n",
    "        if np.any(np.isnan(norm_data_activity[idx_model, inumenv, idx_mouse])):\n",
    "            print(f\"NaN values in norm_data_activity for model {idx_model}, env {inumenv}, mouse {idx_mouse}\")\n",
    "        if np.any(np.isnan(norm_data_placefields[idx_model, inumenv, idx_mouse])):\n",
    "            print(f\"NaN values in norm_data_placefields for model {idx_model}, env {inumenv}, mouse {idx_mouse}\")\n",
    "        ax[0].plot(range(1, max_dims+1), norm_data_activity[idx_model, inumenv, idx_mouse].T, color=reference_color, linestyle=linestyle_model[imodel], label=full_label)\n",
    "        ax[0].plot(range(1, max_dims+1), norm_data_placefields[idx_model, inumenv, idx_mouse].T, color=color_model[imodel], linestyle=linestyle_model[imodel], label=pf_label)\n",
    "ax[0].set_xlabel(\"Dimension\")\n",
    "ax[0].set_ylabel(\"Variance\")\n",
    "ax[0].legend(loc=\"upper right\", fontsize=12)\n",
    "ax[0].set_title(\"Example Mouse\")\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlim(xlim)\n",
    "ax[0].set_ylim(ylim)\n",
    "format_spines(ax[0], x_pos=-0.02, y_pos=-0.02, xbounds=xlim, xticks=xticks, ybounds=ylim)\n",
    "\n",
    "\n",
    "ylim = (0, 1)\n",
    "for imodel, idx_model in enumerate([idx_model_0, idx_model_1]):\n",
    "    full_label = \"Full\" if imodel == 0 else None\n",
    "    pf_label = model_label[imodel]\n",
    "    for inumenv in [0, 2]:\n",
    "        errorPlot(range(1, max_dims+1), csnorm_data_activity[idx_model, inumenv], axis=0, ax=ax[1], se=False, color=reference_color, linestyle=linestyle_model[imodel], label=full_label, alpha=0.1)\n",
    "        errorPlot(range(1, max_dims+1), csnorm_data_placefields[idx_model, inumenv], axis=0, ax=ax[1], se=False, color=color_model[imodel], linestyle=linestyle_model[imodel], label=pf_label, alpha=0.1)\n",
    "ax[1].set_xlabel(\"Dimension\")\n",
    "ax[1].set_ylabel(\"Cum. Variance\")\n",
    "ax[1].set_title(\"Across Mice\")\n",
    "format_spines(ax[1], x_pos=-0.02, y_pos=-0.02, xbounds=xlim, xticks=xticks, ybounds=ylim, yticks=ylim)\n",
    "\n",
    "show_envs = [0, 1, 2]\n",
    "xbounds = (0, len(show_envs)-1)\n",
    "xlim = (-0.5, len(show_envs)-0.5)\n",
    "ylim = (0, 1)\n",
    "for imodel, idx_model in enumerate([idx_model_0, idx_model_1]):\n",
    "    color = color_model[imodel]\n",
    "    for ii, idx in enumerate(show_envs):\n",
    "        ilast = (idx + 1) * 100 - 1\n",
    "        c_data_activity = csnorm_data_activity[idx_model, idx, :, ilast - 1]\n",
    "        c_data_placefields = csnorm_data_placefields[idx_model, idx, :, ilast - 1]\n",
    "        c_fraction = c_data_placefields / c_data_activity\n",
    "        c_valid_fraction = c_fraction[~np.isnan(c_fraction)]\n",
    "        ax[2].plot(ii + beewidth*beeswarm(c_valid_fraction), c_valid_fraction, color=color, marker=\".\", linestyle=\"none\")\n",
    "ax[2].set_xlim(xlim)\n",
    "ax[2].set_ylim(ylim)\n",
    "ax[2].set_xlabel(\"Num Envs\")\n",
    "ax[2].set_ylabel(\"Fractional Variance\")\n",
    "format_spines(ax[2], x_pos=-0.02, y_pos=-0.02, xbounds=xbounds, ybounds=ylim)\n",
    "ax[2].set_xticks(range(len(show_envs)))\n",
    "ax[2].set_xticklabels([f\"{idx + 1}\" for idx in show_envs])\n",
    "ax[2].set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "ax[2].set_yticklabels([0, '', '', '', 1])\n",
    "\n",
    "# model_name = {\n",
    "#     0: \"pca\",\n",
    "#     1: \"covcov\",\n",
    "#     2: \"covcov_correlation\",\n",
    "# }\n",
    "# figure_path = registry.registry_paths.figure_path / \"subspace_analysis\" / f\"{model_name[idx_model]}_subspace_basic_figure\"\n",
    "# # save_figure(fig, figure_path)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c188b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_resample(data: torch.Tensor, num_samples: int | None = None):\n",
    "    N = data.shape[0]\n",
    "    num_samples = num_samples or data.shape[1]\n",
    "    mu = torch.mean(data, dim=1, keepdim=True)\n",
    "    cov = torch.cov(data)\n",
    "    eval, evec = torch.linalg.eigh(cov)\n",
    "    dev = evec @ torch.diag(torch.sqrt(torch.clamp_min(eval, 0.0))) @ torch.randn(N, num_samples)\n",
    "    return dev + mu\n",
    "\n",
    "session = sessiondb.iter_sessions(imaging=True)[0]\n",
    "\n",
    "model = get_subspace(\"covcov_crossvalidated_subspace\", registry)\n",
    "hyperparameters = model.hyperparameters\n",
    "nan_safe = False\n",
    "spks_type = \"oasis\"\n",
    "train_data, frame_behavior_train0, num_neurons = model.get_session_data(session, spks_type, \"train\", use_cell_split=False)\n",
    "train_data = model._center_data(train_data, True)\n",
    "\n",
    "n_keep = int(train_data.shape[1] * 0.3)\n",
    "train_data = train_data[:n_keep]\n",
    "\n",
    "cov1 = torch.cov(train_data)\n",
    "\n",
    "resample1 = gaussian_resample(train_data, train_data.shape[1] * 20)\n",
    "rscov1 = torch.cov(resample1)\n",
    "\n",
    "max_val = np.max(np.abs(np.stack([cov1, rscov1, cov1 - rscov1]))) / 20\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 5), layout=\"constrained\")\n",
    "ax[0].imshow(cov1, cmap=\"bwr\", vmin=-max_val, vmax=max_val)\n",
    "ax[1].imshow(rscov1, cmap=\"bwr\", vmin=-max_val, vmax=max_val)\n",
    "ax[2].imshow(cov1 - rscov1, cmap=\"bwr\", vmin=-max_val, vmax=max_val)\n",
    "ax[3].scatter(cov1.flatten(), rscov1.flatten(), alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sessiondb.iter_sessions(imaging=True)[0]\n",
    "\n",
    "model = get_subspace(\"covcov_crossvalidated_subspace\", registry)\n",
    "hyperparameters = model.hyperparameters\n",
    "nan_safe = False\n",
    "spks_type = \"oasis\"\n",
    "\n",
    "split0 = \"train0\"\n",
    "split1 = \"train1\"\n",
    "train0_data, frame_behavior_train0, num_neurons = model.get_session_data(session, spks_type, split0, use_cell_split=False)\n",
    "train1_data, _, _ = model.get_session_data(session, spks_type, split1, use_cell_split=False)\n",
    "train0_data = model._center_data(train0_data, model.centered)\n",
    "train1_data = model._center_data(train1_data, model.centered)\n",
    "\n",
    "# Generate gaussian resampled data\n",
    "gauss0_data = gaussian_resample(train0_data)\n",
    "gauss1_data = gaussian_resample(train1_data)\n",
    "\n",
    "dist_edges = model._get_placefield_dist_edges(session, hyperparameters)\n",
    "placefield0 = get_placefield(\n",
    "    train0_data.T.numpy(),\n",
    "    frame_behavior_train0,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=hyperparameters.smooth_width,\n",
    ")\n",
    "placefield0_extended = torch.tensor(placefield0.placefield).reshape(-1, num_neurons).T\n",
    "\n",
    "pfgauss0 = get_placefield(\n",
    "    gauss0_data.T.numpy(),\n",
    "    frame_behavior_train0,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=hyperparameters.smooth_width,\n",
    ")\n",
    "pfgauss0_extended = torch.tensor(pfgauss0.placefield).reshape(-1, num_neurons).T\n",
    "\n",
    "# Check for NaNs and filter if needed\n",
    "placefield0_extended, train0_data = model._check_and_filter_nans(placefield0_extended, train0_data, nan_safe=nan_safe)\n",
    "\n",
    "num_components = model._compute_num_components(model.max_components, train0_data.shape, train1_data.shape, placefield0_extended.shape)\n",
    "\n",
    "# Get the root covariance matrices for activity in each split\n",
    "if model.match_dimensions:\n",
    "    pca_activity0 = PCA(num_components=num_components).fit(train0_data)\n",
    "    pca_activity1 = PCA(num_components=num_components).fit(train1_data)\n",
    "    pca_gauss0 = PCA(num_components=num_components).fit(gauss0_data)\n",
    "    pca_gauss1 = PCA(num_components=num_components).fit(gauss1_data)\n",
    "else:\n",
    "    pca_activity0 = PCA().fit(train0_data)\n",
    "    pca_activity1 = PCA().fit(train1_data)\n",
    "    pca_gauss0 = PCA().fit(gauss0_data)\n",
    "    pca_gauss1 = PCA().fit(gauss1_data)\n",
    "components0 = pca_activity0.get_components()\n",
    "components1 = pca_activity1.get_components()\n",
    "eigenvalues0 = pca_activity0.get_eigenvalues()\n",
    "eigenvalues1 = pca_activity1.get_eigenvalues()\n",
    "root_cov_activity0 = components0 @ torch.diag(torch.sqrt(eigenvalues0)) @ components0.T\n",
    "root_cov_activity1 = components1 @ torch.diag(torch.sqrt(eigenvalues1)) @ components1.T\n",
    "\n",
    "# Gauss version\n",
    "components_gauss0 = pca_gauss0.get_components()\n",
    "components_gauss1 = pca_gauss1.get_components()\n",
    "eigenvalues_gauss0 = pca_gauss0.get_eigenvalues()\n",
    "eigenvalues_gauss1 = pca_gauss1.get_eigenvalues()\n",
    "root_cov_gauss0 = components_gauss0 @ torch.diag(torch.sqrt(eigenvalues_gauss0)) @ components_gauss0.T\n",
    "root_cov_gauss1 = components_gauss1 @ torch.diag(torch.sqrt(eigenvalues_gauss1)) @ components_gauss1.T\n",
    "\n",
    "# Get the root covariance matrices for place fields in the first half split\n",
    "pca_placefields0 = PCA(num_components=num_components).fit(placefield0_extended)\n",
    "pf_components0 = pca_placefields0.get_components()\n",
    "pf_eigenvalues0 = pca_placefields0.get_eigenvalues()\n",
    "root_cov_placefields0 = pf_components0 @ torch.diag(torch.sqrt(pf_eigenvalues0)) @ pf_components0.T\n",
    "\n",
    "# Gauss version\n",
    "pca_pfgauss0 = PCA(num_components=num_components).fit(pfgauss0_extended)\n",
    "pf_components_gauss0 = pca_pfgauss0.get_components()\n",
    "pf_eigenvalues_gauss0 = pca_pfgauss0.get_eigenvalues()\n",
    "root_cov_pfgauss0 = pf_components_gauss0 @ torch.diag(torch.sqrt(pf_eigenvalues_gauss0)) @ pf_components_gauss0.T\n",
    "\n",
    "# Measure SVD on activity vs activity or PFs vs activity\n",
    "SVCA_activity = SVCA(centered=False, num_components=num_components).fit(root_cov_activity0, root_cov_activity1)\n",
    "SVCA_placefields = SVCA(centered=False, num_components=num_components).fit(root_cov_placefields0, root_cov_activity1)\n",
    "\n",
    "SVCA_activity_gauss = SVCA(centered=False, num_components=num_components).fit(root_cov_gauss0, root_cov_gauss1)\n",
    "SVCA_placefields_gauss = SVCA(centered=False, num_components=num_components).fit(root_cov_pfgauss0, root_cov_gauss1)\n",
    "\n",
    "subspace = Subspace(\n",
    "    subspace_activity=SVCA_activity,\n",
    "    subspace_placefields=SVCA_placefields,\n",
    "    extras=dict(placefield0=placefield0),\n",
    ")\n",
    "\n",
    "# Then test\n",
    "split0 = \"validation\"\n",
    "split1 = \"test\"\n",
    "test0_data, frame_behavior_test0, num_neurons = model.get_session_data(session, spks_type, split0, use_cell_split=False)\n",
    "test1_data, _, _ = model.get_session_data(session, spks_type, split1, use_cell_split=False)\n",
    "test0_data = model._center_data(test0_data, model.centered)\n",
    "test1_data = model._center_data(test1_data, model.centered)\n",
    "\n",
    "# Gauss version\n",
    "gauss0_test = gaussian_resample(test0_data)\n",
    "gauss1_test = gaussian_resample(test1_data)\n",
    "\n",
    "dist_edges = model._get_placefield_dist_edges(session, hyperparameters)\n",
    "placefield0 = get_placefield(\n",
    "    test0_data.T.numpy(),\n",
    "    frame_behavior_test0,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=hyperparameters.smooth_width,\n",
    ")\n",
    "placefield0_extended = torch.tensor(placefield0.placefield).reshape(-1, num_neurons).T\n",
    "\n",
    "pfgauss0 = get_placefield(\n",
    "    gauss0_test.T.numpy(),\n",
    "    frame_behavior_test0,\n",
    "    dist_edges=dist_edges,\n",
    "    average=True,\n",
    "    smooth_width=hyperparameters.smooth_width,\n",
    ")   \n",
    "pfgauss0_extended = torch.tensor(pfgauss0.placefield).reshape(-1, num_neurons).T\n",
    "\n",
    "# Check for NaNs and filter if needed\n",
    "placefield0_extended, test0_data = model._check_and_filter_nans(placefield0_extended, test0_data, nan_safe=nan_safe)\n",
    "\n",
    "num_components = model._compute_num_components(model.max_components, test0_data.shape, test1_data.shape, placefield0_extended.shape)\n",
    "\n",
    "# Get the root covariance matrices for activity in each split\n",
    "if model.match_dimensions:\n",
    "    pca_activity0 = PCA(num_components=num_components).fit(test0_data)\n",
    "    pca_activity1 = PCA(num_components=num_components).fit(test1_data)\n",
    "    pca_gauss0 = PCA(num_components=num_components).fit(gauss0_test)\n",
    "    pca_gauss1 = PCA(num_components=num_components).fit(gauss1_test)\n",
    "else:\n",
    "    pca_activity0 = PCA().fit(test0_data)\n",
    "    pca_activity1 = PCA().fit(test1_data)\n",
    "    pca_gauss0 = PCA().fit(gauss0_test)\n",
    "    pca_gauss1 = PCA().fit(gauss1_test)\n",
    "components0 = pca_activity0.get_components()\n",
    "components1 = pca_activity1.get_components()\n",
    "eigenvalues0 = pca_activity0.get_eigenvalues()\n",
    "eigenvalues1 = pca_activity1.get_eigenvalues()\n",
    "root_cov_activity0 = components0 @ torch.diag(torch.sqrt(eigenvalues0)) @ components0.T\n",
    "root_cov_activity1 = components1 @ torch.diag(torch.sqrt(eigenvalues1)) @ components1.T\n",
    "\n",
    "# Gauss version \n",
    "components_gauss0 = pca_gauss0.get_components() \n",
    "components_gauss1 = pca_gauss1.get_components()\n",
    "eigenvalues_gauss0 = pca_gauss0.get_eigenvalues()\n",
    "eigenvalues_gauss1 = pca_gauss1.get_eigenvalues()\n",
    "root_cov_gauss0 = components_gauss0 @ torch.diag(torch.sqrt(eigenvalues_gauss0)) @ components_gauss0.T\n",
    "root_cov_gauss1 = components_gauss1 @ torch.diag(torch.sqrt(eigenvalues_gauss1)) @ components_gauss1.T\n",
    "\n",
    "# Get the root covariance matrices for place fields in the first half split\n",
    "pca_placefields0 = PCA(num_components=num_components).fit(placefield0_extended)\n",
    "pf_components0 = pca_placefields0.get_components()\n",
    "pf_eigenvalues0 = pca_placefields0.get_eigenvalues()\n",
    "root_cov_placefields0 = pf_components0 @ torch.diag(torch.sqrt(pf_eigenvalues0)) @ pf_components0.T\n",
    "\n",
    "# Gauss version \n",
    "pca_pfgauss0 = PCA(num_components=num_components).fit(pfgauss0_extended)\n",
    "pf_components_gauss0 = pca_pfgauss0.get_components()\n",
    "pf_eigenvalues_gauss0 = pca_pfgauss0.get_eigenvalues()\n",
    "root_cov_pfgauss0 = pf_components_gauss0 @ torch.diag(torch.sqrt(pf_eigenvalues_gauss0)) @ pf_components_gauss0.T\n",
    "\n",
    "# variance activity\n",
    "variance_activity = subspace.subspace_activity.score(root_cov_activity0, root_cov_activity1, normalize=False)[0]\n",
    "variance_placefields = subspace.subspace_placefields.score(root_cov_placefields0, root_cov_activity1, normalize=False)[0]\n",
    "\n",
    "# Gauss version\n",
    "variance_activity_gauss = SVCA_activity_gauss.score(root_cov_gauss0, root_cov_gauss1, normalize=False)[0]\n",
    "variance_placefields_gauss = SVCA_placefields_gauss.score(root_cov_pfgauss0, root_cov_gauss1, normalize=False)[0]\n",
    "\n",
    "variance = dict(\n",
    "    variance_activity=variance_activity,\n",
    "    variance_placefields=variance_placefields,\n",
    "    variance_activity_gauss=variance_activity_gauss,\n",
    "    variance_placefields_gauss=variance_placefields_gauss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e01d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xscale = \"log\"\n",
    "yscale = \"linear\"\n",
    "\n",
    "num_dimensions = variance_activity.shape[0]\n",
    "xvals = torch.arange(num_dimensions) + 1\n",
    "negs_activity = torch.where(variance_activity < 0)[0]\n",
    "negs_placefields = torch.where(variance_placefields < 0)[0]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(xvals, variance_activity / torch.sum(variance_activity), color=\"k\", linewidth=1.0)\n",
    "ax[0].plot(xvals, variance_placefields / torch.sum(variance_activity), color=\"b\", linewidth=1.0)\n",
    "ax[0].scatter(negs_activity, -0.01 * torch.ones(negs_activity.shape[0]), c=\"k\", s=5, alpha=0.3)\n",
    "ax[0].scatter(negs_placefields, -0.02 * torch.ones(negs_placefields.shape[0]), c=\"b\", s=5, alpha=0.3)\n",
    "ax[0].set_xscale(xscale)\n",
    "ax[0].set_yscale(yscale)\n",
    "ax[0].set_xlabel(\"Dimension\")\n",
    "ax[0].set_ylabel(\"Variance\")\n",
    "ax[0].legend([\"Activity\", \"Placefields\"])\n",
    "ax[0].set_title(\"Variance\")\n",
    "\n",
    "negs_activity_gauss = torch.where(variance_activity_gauss < 0)[0]\n",
    "negs_placefields_gauss = torch.where(variance_placefields_gauss < 0)[0]\n",
    "\n",
    "ax[1].plot(xvals, variance_activity_gauss / torch.sum(variance_activity_gauss), color=\"k\", linewidth=1.0)\n",
    "ax[1].plot(xvals, variance_placefields_gauss / torch.sum(variance_activity_gauss), color=\"b\", linewidth=1.0)\n",
    "ax[1].scatter(negs_activity_gauss, -0.01 * torch.ones(negs_activity_gauss.shape[0]), c=\"k\", s=5, alpha=0.3)\n",
    "ax[1].scatter(negs_placefields_gauss, -0.02 * torch.ones(negs_placefields_gauss.shape[0]), c=\"b\", s=5, alpha=0.3)\n",
    "ax[1].set_xscale(xscale)\n",
    "ax[1].set_yscale(yscale)\n",
    "ax[1].set_xlabel(\"Dimension\")\n",
    "ax[1].set_ylabel(\"Variance\")\n",
    "ax[1].legend([\"Activity\", \"Placefields\"])\n",
    "ax[1].set_title(\"Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6e77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27912a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682371e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c91aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0aceff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cdf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7630903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block runs a simulation to check if interleaved cross-covcov method is same as block version\n",
    "num_samples = 100000\n",
    "num_neurons = 100\n",
    "num_components = 100\n",
    "num_source = 50\n",
    "\n",
    "# Generate eigenspectrum\n",
    "eigenvalues = 1.2 ** -torch.arange(num_components)\n",
    "same_fraction = 0.9\n",
    "_ev_shared = torch.randn(num_neurons, num_neurons)\n",
    "eigenvectors_train = torch.linalg.qr(same_fraction * _ev_shared + (1-same_fraction) * torch.randn(num_neurons, num_neurons)).Q[:, :num_components]\n",
    "eigenvectors_test = torch.linalg.qr(same_fraction * _ev_shared + (1-same_fraction) * torch.randn(num_neurons, num_neurons)).Q[:, :num_components]\n",
    "\n",
    "# Generate random data\n",
    "train_data = eigenvectors_train @ torch.diag(torch.sqrt(eigenvalues)) @ torch.randn(num_components, num_samples)\n",
    "test_data = eigenvectors_test @ torch.diag(torch.sqrt(eigenvalues)) @ torch.randn(num_components, num_samples)\n",
    "\n",
    "train_source = train_data[:num_source]\n",
    "train_target = train_data[num_source:]\n",
    "test_source = test_data[:num_source]\n",
    "test_target = test_data[num_source:]\n",
    "\n",
    "test_crcov = test_source @ test_target.T\n",
    "\n",
    "# Train PCAs\n",
    "pca_source = PCA().fit(train_source)\n",
    "pca_target = PCA().fit(train_target)\n",
    "\n",
    "# Interleaved cross-covcov metric\n",
    "train_source_evecs = pca_source.get_components()\n",
    "train_source_eval = torch.diag(torch.sqrt(pca_source.get_eigenvalues()))\n",
    "train_target_evecs = pca_target.get_components()\n",
    "train_target_eval = torch.diag(torch.sqrt(pca_target.get_eigenvalues()))\n",
    "\n",
    "inner_block_activity = train_source_eval @ train_source_evecs.T @ test_crcov @ train_target_evecs @ train_target_eval\n",
    "inner_block_interleaved = train_target_eval @ train_target_evecs.T @ test_crcov @ train_source_evecs @ train_source_eval\n",
    "\n",
    "variance_block = torch.sqrt(torch.flipud(torch.linalg.eigvalsh(inner_block_activity)))\n",
    "variance_interleaved = torch.sqrt(torch.flipud(torch.linalg.eigvalsh(inner_block_interleaved)))\n",
    "\n",
    "plt.close('all')\n",
    "plt.plot(variance_block, c='k')\n",
    "plt.plot(variance_interleaved, c='b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
